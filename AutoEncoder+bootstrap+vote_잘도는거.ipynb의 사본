{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AutoEncoder+bootstrap+vote.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1GtDfKW90iDn_irx9Ij7ckkNpI2VtLWvQ","authorship_tag":"ABX9TyOhePURJ9JK1Awfj9Z5NsSx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"08a2da59f2f742ae877ff835669dd129":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_14021f8470174da9a7747f73f2a30f56","IPY_MODEL_512a30b3a4ae4ba097bf8c11e2af74f8"],"layout":"IPY_MODEL_3f5c0e64c3ec48fbbccbaaab59636c5c"}},"14021f8470174da9a7747f73f2a30f56":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d96d19e5a44a41a384cf518328a9b983","placeholder":"​","style":"IPY_MODEL_3c33f01ed8bf42bab5732babb17f9786","value":"0.033 MB of 0.033 MB uploaded (0.000 MB deduped)\r"}},"512a30b3a4ae4ba097bf8c11e2af74f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_39fd2bfbd7ec479e944184f2723a9c62","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad4ab410bc85426e879b7d1a33bcb081","value":1}},"3f5c0e64c3ec48fbbccbaaab59636c5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d96d19e5a44a41a384cf518328a9b983":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c33f01ed8bf42bab5732babb17f9786":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39fd2bfbd7ec479e944184f2723a9c62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad4ab410bc85426e879b7d1a33bcb081":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","# drive.mount('/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data')\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/IITP/sohyun/creditcard_prediction/data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aoTfHzuB_M7u","executionInfo":{"status":"ok","timestamp":1659485894026,"user_tz":-540,"elapsed":11793,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"3cc51d75-d6bf-4c3c-a410-490ba6410077"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data\n"]}]},{"cell_type":"code","source":["!pip install wandb -qqq\n","import wandb\n","wandb.login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"id":"pyCrbam-X2js","executionInfo":{"status":"ok","timestamp":1659485928851,"user_tz":-540,"elapsed":30778,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"b17d6bce-a99c-4694-deed-acd1aec35f37"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.8 MB 14.0 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 66.6 MB/s \n","\u001b[K     |████████████████████████████████| 181 kB 72.1 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "]},{"name":"stdout","output_type":"stream","text":["··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","execution_count":34,"metadata":{"id":"gPauNGcl-kic","executionInfo":{"status":"ok","timestamp":1659493125923,"user_tz":-540,"elapsed":3,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"outputs":[],"source":["import random\n","import pandas as pd\n","import numpy as np\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","EPOCHS = 300 #65 ## 400\n","LR = 1e-2\n","BS = 8096 #16384\n","SEED = 1004\n","\n","# wandb.init(project=\"\") # wandb init\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","source":["class MyDataset(Dataset):\n","    def __init__(self, df, eval_mode):\n","        self.df = df\n","        self.eval_mode = eval_mode\n","        if self.eval_mode:\n","            self.labels = self.df['Class'].values\n","            self.df = self.df.drop(columns=['Class']).values\n","        else:\n","            self.df = self.df.values\n","        \n","    def __getitem__(self, index):\n","        if self.eval_mode:\n","            self.x = self.df[index]\n","            self.y = self.labels[index]\n","            return torch.Tensor(self.x), self.y\n","        else:\n","            self.x = self.df[index]\n","            return torch.Tensor(self.x)\n","        \n","    def __len__(self):\n","        return len(self.df)\n","\n","class AutoEncoder(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","        self.Encoder = nn.Sequential(\n","            nn.Linear(30,64),\n","            nn.BatchNorm1d(64),\n","            nn.LeakyReLU(),\n","            nn.Linear(64,128),\n","            nn.BatchNorm1d(128),\n","            nn.LeakyReLU(),\n","        )\n","        self.Decoder = nn.Sequential(\n","            nn.Linear(128,64),\n","            nn.BatchNorm1d(64),\n","            nn.LeakyReLU(),\n","            nn.Linear(64,30),\n","        )\n","        \n","    def forward(self, x):\n","        x = self.Encoder(x)\n","        x = self.Decoder(x)\n","        return x\n","\n","class Trainer():\n","    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.scheduler = scheduler\n","        self.device = device\n","        # Loss Function\n","        self.criterion = nn.L1Loss().to(self.device)\n","        \n","    def fit(self, modelNum):\n","        self.model.to(self.device)\n","        best_score = 0\n","        for epoch in range(EPOCHS):\n","            self.model.train()\n","            train_loss = []\n","            for x in iter(self.train_loader):\n","                x = x.float().to(self.device)\n","                self.optimizer.zero_grad()\n","\n","                _x = self.model(x)\n","                loss = self.criterion(x, _x)\n","\n","                loss.backward()\n","                self.optimizer.step()\n","\n","                train_loss.append(loss.item())\n","\n","            score = self.validation(self.model, 0.94)\n","            # print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n","            \n","            wandb.log({\n","                \"validation f1\": score,\n","                \"loss\": loss\n","            })\n","            if self.scheduler is not None:\n","              self.scheduler.step(score)\n","\n","            if best_score < score:\n","              print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n","              best_score = score\n","              torch.save(self.model.module.state_dict(), f'./best_model{modelNum}.pth', _use_new_zipfile_serialization=False)\n","  \n","    def validation(self, eval_model, thr):\n","        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","        eval_model.eval()\n","        pred = []\n","        true = []\n","        with torch.no_grad():\n","            for x, y in iter(self.val_loader):\n","                x = x.float().to(self.device)\n","\n","                _x = self.model(x)\n","                diff = cos(x, _x).cpu().tolist()\n","                batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n","                pred += batch_pred\n","                true += y.tolist()\n","\n","        return f1_score(true, pred, average='macro')"],"metadata":{"id":"kijk5u73jo-B","executionInfo":{"status":"ok","timestamp":1659493145897,"user_tz":-540,"elapsed":372,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def prediction(model, thr, test_loader, device):\n","  model.to(device)\n","  model.eval()\n","  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","  pred = []\n","  with torch.no_grad():\n","    for x in iter(test_loader):\n","      x = x.float().to(device)\n","      \n","      _x = model(x)\n","      \n","      diff = cos(x, _x).cpu().tolist()\n","      batch_pred = np.where(np.array(diff)<thr, 1, 0).tolist()\n","      pred += batch_pred\n","  return pred"],"metadata":{"id":"z2KhkzS2QK_r","executionInfo":{"status":"ok","timestamp":1659493147330,"user_tz":-540,"elapsed":15,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["def main(config):\n","  seed_everything(SEED) # Seed fix\n","\n","  #---# DATA #---#\n","  train_df = pd.read_csv('./train.csv')\n","  train_df = train_df.drop(columns=['ID'])\n","  val_df = pd.read_csv('./val.csv')\n","  val_df = val_df.drop(columns=['ID'])\n","  test_df = pd.read_csv('./test.csv')\n","  test_df = test_df.drop(columns=['ID'])\n","  models = [] # list of models\n","\n","  import numpy as np\n","\n","  val_dataset = MyDataset(df = val_df, eval_mode=True)\n","  val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False)\n","  test_dataset = MyDataset(test_df, False)\n","  test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=6)\n","\n","  for i in range(config.K):\n","    choose_idx = np.random.choice(train_df.shape[0], 100000, replace=True)\n","    train_df_choose = train_df.loc[choose_idx,:]\n","    train_dataset = MyDataset(df=train_df_choose, eval_mode=False)\n","    train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n","\n","    model = nn.DataParallel(AutoEncoder())\n","    model.eval()\n","    optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n","\n","    trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n","    trainer.fit(modelNum=(i+1))\n","\n","    models.append(model)\n","\n","  # # for test\n","  # model_preds = []\n","  # for i in range(config.K):\n","  #   model = AutoEncoder()\n","  #   model.load_state_dict(torch.load(f'./best_model{(i+1)}.pth'))\n","  #   model = nn.DataParallel(model)\n","  #   model.eval()\n","  #   preds = prediction(model, 0.97, test_loader, device)\n","  #   model_preds.append(preds)\n","\n","  # model_pred_df = pd.DataFrame(model_preds).transpose()\n","  # row_sum = model_pred_df.sum(axis=1)\n","  # pred = np.where(row_sum > 3, 1, 0) # 클수록 anomaly\n","  \n","  # return pred\n","\n","\n","if __name__ == '__main__':\n","  wandb.init()\n","  import easydict\n","  args = easydict.EasyDict({\n","      \"K\" : 10,\n","  })\n","  config = args\n","\n","  print('------------ Options -------------')\n","  for k, v in sorted(args.items()):\n","    print('%s: %s' % (str(k), str(v)))\n","  print('-------------- End ----------------')\n","\n","  pred = main(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["08a2da59f2f742ae877ff835669dd129","14021f8470174da9a7747f73f2a30f56","512a30b3a4ae4ba097bf8c11e2af74f8","3f5c0e64c3ec48fbbccbaaab59636c5c","d96d19e5a44a41a384cf518328a9b983","3c33f01ed8bf42bab5732babb17f9786","39fd2bfbd7ec479e944184f2723a9c62","ad4ab410bc85426e879b7d1a33bcb081"]},"id":"MOLXoEwK8TqY","executionInfo":{"status":"ok","timestamp":1659500269190,"user_tz":-540,"elapsed":4157639,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"fb944538-4be6-4af3-df95-f52e1f871977"},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:whtetxhf) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08a2da59f2f742ae877ff835669dd129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▅▂▂▂▁▂▁▂█▃▃▂▁▁▁▂▆▃▂▂▂▁▂▁▅▃▂▂▁▁▁▁▄▃▂▁▂▁▁▁</td></tr><tr><td>validation f1</td><td>▂▅▁▁▁▁▁▁▁▇▇▇▇▇▇▇▁▇██████▁▆██████▂▅██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.03323</td></tr><tr><td>validation f1</td><td>0.91658</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">stoic-eon-316</strong>: <a href=\"https://wandb.ai/sohyun/uncategorized/runs/whtetxhf\" target=\"_blank\">https://wandb.ai/sohyun/uncategorized/runs/whtetxhf</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220803_021908-whtetxhf/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:whtetxhf). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.21"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data/wandb/run-20220803_030831-13pxgc36</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/sohyun/uncategorized/runs/13pxgc36\" target=\"_blank\">sleek-dragon-317</a></strong> to <a href=\"https://wandb.ai/sohyun/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------------ Options -------------\n","K: 10\n","-------------- End ----------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch : [0] Train loss : [0.4755678681226877] Val Score : [0.08950372660924241])\n","Epoch : [1] Train loss : [0.2710765279256381] Val Score : [0.3931564343359303])\n","Epoch : [2] Train loss : [0.1941639528824733] Val Score : [0.48242171514683446])\n","Epoch : [3] Train loss : [0.16045551002025604] Val Score : [0.4964287240054909])\n","Epoch : [4] Train loss : [0.14065572390189537] Val Score : [0.5017886051269973])\n","Epoch : [5] Train loss : [0.1312140146127114] Val Score : [0.504963036299151])\n","Epoch : [6] Train loss : [0.12256172471321546] Val Score : [0.5058766468706869])\n","Epoch : [7] Train loss : [0.11931822792841838] Val Score : [0.5074018909665472])\n","Epoch : [8] Train loss : [0.11618078041535157] Val Score : [0.5082113813746426])\n","Epoch : [9] Train loss : [0.10967019429573646] Val Score : [0.5099898644592141])\n","Epoch : [10] Train loss : [0.10626890682257138] Val Score : [0.5107544588227518])\n","Epoch : [11] Train loss : [0.10179285934338203] Val Score : [0.5124167372311219])\n","Epoch : [12] Train loss : [0.09694954237112632] Val Score : [0.5138345496627801])\n","Epoch : [13] Train loss : [0.09680605622438285] Val Score : [0.5187218979584981])\n","Epoch : [14] Train loss : [0.09206708520650864] Val Score : [0.5252513412739617])\n","Epoch : [15] Train loss : [0.09031322025335752] Val Score : [0.5336815796643095])\n","Epoch : [16] Train loss : [0.08856373394911106] Val Score : [0.5388197931061621])\n","Epoch : [17] Train loss : [0.08411035629419181] Val Score : [0.543607959163492])\n","Epoch : [18] Train loss : [0.08292219558587441] Val Score : [0.5503382885175849])\n","Epoch : [19] Train loss : [0.07909697351547387] Val Score : [0.5576332952351725])\n","Epoch : [20] Train loss : [0.07712286710739136] Val Score : [0.5602396081679595])\n","Epoch : [21] Train loss : [0.0761007689512693] Val Score : [0.5623293856908199])\n","Epoch : [22] Train loss : [0.07496790530589911] Val Score : [0.5647384131310997])\n","Epoch : [23] Train loss : [0.07593239442660259] Val Score : [0.5711926323803983])\n","Epoch : [24] Train loss : [0.07364059698123199] Val Score : [0.584088028027516])\n","Epoch : [25] Train loss : [0.07301223278045654] Val Score : [0.6090673860606592])\n","Epoch : [26] Train loss : [0.07301155076577114] Val Score : [0.6765036683764233])\n","Epoch : [27] Train loss : [0.07364567369222641] Val Score : [0.7267446884090669])\n","Epoch : [29] Train loss : [0.06584424496843265] Val Score : [0.7353562550268086])\n","Epoch : [34] Train loss : [0.06397317149318181] Val Score : [0.7422520697342344])\n","Epoch : [36] Train loss : [0.061482035769866064] Val Score : [0.74464046996434])\n","Epoch : [40] Train loss : [0.061550481674762875] Val Score : [0.7495600450513867])\n","Epoch : [42] Train loss : [0.05990606231185106] Val Score : [0.75467969893057])\n","Epoch 00054: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch 00065: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch 00076: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch 00087: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch 00098: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch 00109: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch 00120: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch 00131: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00142: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch 00153: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00164: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00175: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch 00186: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch 00197: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00208: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00219: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00230: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch 00241: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch 00252: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [0] Train loss : [0.4731028309235206] Val Score : [0.07101525628849586])\n","Epoch : [1] Train loss : [0.2664742492712461] Val Score : [0.4029954903796822])\n","Epoch : [2] Train loss : [0.19093813002109528] Val Score : [0.4740753487839797])\n","Epoch : [3] Train loss : [0.1594914301083638] Val Score : [0.49571583191871493])\n","Epoch : [4] Train loss : [0.14182877425964063] Val Score : [0.5011250904581092])\n","Epoch : [5] Train loss : [0.13020670184722313] Val Score : [0.5041410174273849])\n","Epoch : [6] Train loss : [0.12456814142373893] Val Score : [0.507308303204048])\n","Epoch : [7] Train loss : [0.11702737556054042] Val Score : [0.5076137062782945])\n","Epoch : [8] Train loss : [0.11017491496526279] Val Score : [0.512531729649527])\n","Epoch : [9] Train loss : [0.10899197768706542] Val Score : [0.5265739619685208])\n","Epoch : [10] Train loss : [0.10249715241102073] Val Score : [0.5360877494307982])\n","Epoch : [11] Train loss : [0.09901825739787175] Val Score : [0.5389894609401439])\n","Epoch : [12] Train loss : [0.09635319216893269] Val Score : [0.5407464427013711])\n","Epoch : [13] Train loss : [0.09018062570920357] Val Score : [0.5423323635070021])\n","Epoch : [14] Train loss : [0.09123360365629196] Val Score : [0.545687326564355])\n","Epoch : [15] Train loss : [0.08739265455649449] Val Score : [0.5474631286456717])\n","Epoch : [16] Train loss : [0.08448863258728614] Val Score : [0.549593983849242])\n","Epoch : [17] Train loss : [0.08282365592626426] Val Score : [0.5509723592989528])\n","Epoch : [19] Train loss : [0.07963838485571054] Val Score : [0.5537826710416633])\n","Epoch : [22] Train loss : [0.07493016238395984] Val Score : [0.5568576743388275])\n","Epoch : [25] Train loss : [0.07444227085663722] Val Score : [0.5582667196871773])\n","Epoch : [27] Train loss : [0.06933634556256808] Val Score : [0.5597358408644433])\n","Epoch : [28] Train loss : [0.06893744090428719] Val Score : [0.5602396081679595])\n","Epoch : [29] Train loss : [0.07060779631137848] Val Score : [0.561795386550052])\n","Epoch : [30] Train loss : [0.06868054030033258] Val Score : [0.5619725081158782])\n","Epoch : [31] Train loss : [0.0707334835941975] Val Score : [0.563606854805332])\n","Epoch : [32] Train loss : [0.06539209588215901] Val Score : [0.5647384131310997])\n","Epoch : [33] Train loss : [0.06476135150744365] Val Score : [0.5661035992102532])\n","Epoch : [34] Train loss : [0.0659926341703305] Val Score : [0.5679345323877522])\n","Epoch : [35] Train loss : [0.06659478121078931] Val Score : [0.5740054732156139])\n","Epoch : [36] Train loss : [0.06448324397206306] Val Score : [0.5811257888292362])\n","Epoch : [37] Train loss : [0.06497836485505104] Val Score : [0.5885849353955984])\n","Epoch : [38] Train loss : [0.06351364346650931] Val Score : [0.6020496313376503])\n","Epoch : [39] Train loss : [0.06063671295459454] Val Score : [0.6409352832618851])\n","Epoch : [40] Train loss : [0.059936651530174107] Val Score : [0.6886720067273666])\n","Epoch : [41] Train loss : [0.05992084884872803] Val Score : [0.7684388896488608])\n","Epoch : [42] Train loss : [0.06058530452159735] Val Score : [0.7713696202996474])\n","Epoch : [43] Train loss : [0.06082098472576875] Val Score : [0.79380975986869])\n","Epoch : [45] Train loss : [0.056838566867204815] Val Score : [0.808369294415656])\n","Epoch : [46] Train loss : [0.05656393388142952] Val Score : [0.8244378451249526])\n","Epoch : [47] Train loss : [0.05798333940597681] Val Score : [0.833113452596645])\n","Epoch : [48] Train loss : [0.05607758175868254] Val Score : [0.8376267560436427])\n","Epoch : [49] Train loss : [0.05464261540999779] Val Score : [0.856966968023358])\n","Epoch : [59] Train loss : [0.05289939762308048] Val Score : [0.8621517488551477])\n","Epoch : [63] Train loss : [0.050339016203696914] Val Score : [0.8674887641844412])\n","Epoch 00075: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch 00086: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch 00097: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch 00108: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch 00119: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch 00130: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch 00141: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch 00152: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00163: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch 00174: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00185: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00196: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch 00207: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch 00218: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00229: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00240: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00251: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch 00262: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch 00273: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [0] Train loss : [0.4548658224252554] Val Score : [0.14288409644276417])\n","Epoch : [1] Train loss : [0.257891609118535] Val Score : [0.36974262126957275])\n","Epoch : [2] Train loss : [0.1911207391665532] Val Score : [0.4632521553479539])\n","Epoch : [3] Train loss : [0.1599382574741657] Val Score : [0.4878051249077051])\n","Epoch : [4] Train loss : [0.1438495287528405] Val Score : [0.5004386933604956])\n","Epoch : [5] Train loss : [0.13041959015222696] Val Score : [0.512018539164737])\n","Epoch : [6] Train loss : [0.12077211187436031] Val Score : [0.5215055681645543])\n","Epoch : [8] Train loss : [0.11072857391375762] Val Score : [0.5259035289777105])\n","Epoch : [9] Train loss : [0.10303845027318367] Val Score : [0.5276979695556785])\n","Epoch : [10] Train loss : [0.09991964640525672] Val Score : [0.5293995060019794])\n","Epoch : [11] Train loss : [0.09911373257637024] Val Score : [0.5336815796643095])\n","Epoch : [12] Train loss : [0.09565553069114685] Val Score : [0.5390746923434317])\n","Epoch : [13] Train loss : [0.09157168349394432] Val Score : [0.5438093350896822])\n","Epoch : [14] Train loss : [0.08787404000759125] Val Score : [0.5466732098311047])\n","Epoch : [15] Train loss : [0.08656339863171944] Val Score : [0.551488958700148])\n","Epoch : [16] Train loss : [0.08461045989623436] Val Score : [0.554204854984325])\n","Epoch : [17] Train loss : [0.08092948163931186] Val Score : [0.5723410221437316])\n","Epoch : [18] Train loss : [0.08012337122972195] Val Score : [0.5866045319852622])\n","Epoch : [19] Train loss : [0.07775656420450944] Val Score : [0.6562726057501772])\n","Epoch : [20] Train loss : [0.07681824324222711] Val Score : [0.6680558781974872])\n","Epoch : [21] Train loss : [0.07494790852069855] Val Score : [0.6858275973539593])\n","Epoch : [22] Train loss : [0.07193363572542484] Val Score : [0.6946258319247834])\n","Epoch : [23] Train loss : [0.0701229446209394] Val Score : [0.7094766927103557])\n","Epoch : [24] Train loss : [0.0730652568432001] Val Score : [0.7206844679680786])\n","Epoch : [26] Train loss : [0.07054212116278134] Val Score : [0.730971061881369])\n","Epoch : [27] Train loss : [0.07013602268237334] Val Score : [0.7376112450647377])\n","Epoch : [30] Train loss : [0.06306724422253095] Val Score : [0.75467969893057])\n","Epoch : [32] Train loss : [0.06420376982826453] Val Score : [0.7600119366040216])\n","Epoch : [36] Train loss : [0.060478047969249576] Val Score : [0.762761970120889])\n","Epoch : [38] Train loss : [0.05890052937544309] Val Score : [0.7684388896488608])\n","Epoch : [39] Train loss : [0.059826862353544966] Val Score : [0.7713696202996474])\n","Epoch : [40] Train loss : [0.057818605922735654] Val Score : [0.7743645687973808])\n","Epoch : [42] Train loss : [0.05898423664844953] Val Score : [0.7870308296420961])\n","Epoch : [45] Train loss : [0.0581005195585581] Val Score : [0.7973199624677456])\n","Epoch : [46] Train loss : [0.05667311382981447] Val Score : [0.808369294415656])\n","Epoch : [48] Train loss : [0.05451524229003833] Val Score : [0.8162006166001039])\n","Epoch : [49] Train loss : [0.05077839413514504] Val Score : [0.8244378451249526])\n","Epoch : [50] Train loss : [0.052774275438143656] Val Score : [0.8376267560436427])\n","Epoch : [52] Train loss : [0.0554463155567646] Val Score : [0.8422634702634115])\n","Epoch : [53] Train loss : [0.05558393236536246] Val Score : [0.872984830495149])\n","Epoch : [55] Train loss : [0.052359543167627774] Val Score : [0.8844834793761085])\n","Epoch : [59] Train loss : [0.05375153198838234] Val Score : [0.890501890608512])\n","Epoch : [60] Train loss : [0.05033470059816654] Val Score : [0.8967110829723166])\n","Epoch : [62] Train loss : [0.05148726386519579] Val Score : [0.9031202878275757])\n","Epoch : [64] Train loss : [0.04926078938520872] Val Score : [0.9097393418694286])\n","Epoch : [67] Train loss : [0.04812661157204555] Val Score : [0.9165787375726882])\n","Epoch 00079: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch 00090: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch 00101: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch 00112: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch 00123: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch 00134: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch 00145: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch 00156: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00167: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch 00178: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00189: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00200: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch 00211: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch 00222: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00233: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00244: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00255: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch 00266: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch 00277: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [0] Train loss : [0.47724255231710583] Val Score : [0.08774370787940464])\n","Epoch : [1] Train loss : [0.2707218596568474] Val Score : [0.40814554650592283])\n","Epoch : [2] Train loss : [0.19100346702795762] Val Score : [0.4722779573439995])\n","Epoch : [3] Train loss : [0.15524043028171247] Val Score : [0.49654336422015294])\n","Epoch : [4] Train loss : [0.13968677245653593] Val Score : [0.5031009503775927])\n","Epoch : [5] Train loss : [0.12856699411685651] Val Score : [0.5049844374152298])\n","Epoch : [6] Train loss : [0.12195013463497162] Val Score : [0.5068224016293257])\n","Epoch : [7] Train loss : [0.11929747061087535] Val Score : [0.5083326079712014])\n","Epoch : [8] Train loss : [0.11053771124436305] Val Score : [0.5097059233701152])\n","Epoch : [9] Train loss : [0.10671807080507278] Val Score : [0.5104087714319103])\n","Epoch : [10] Train loss : [0.102356639619057] Val Score : [0.5112960034486623])\n","Epoch : [11] Train loss : [0.09982058119315368] Val Score : [0.5126472757161177])\n","Epoch : [12] Train loss : [0.09791852648441608] Val Score : [0.5140485539880152])\n","Epoch : [14] Train loss : [0.09155546472622798] Val Score : [0.51445119549275])\n","Epoch : [15] Train loss : [0.09334158381590477] Val Score : [0.51531006027499])\n","Epoch : [16] Train loss : [0.08708894138152783] Val Score : [0.5153749438054094])\n","Epoch : [17] Train loss : [0.08636939124419139] Val Score : [0.517163230237826])\n","Epoch : [18] Train loss : [0.08424172894312786] Val Score : [0.5182395943755592])\n","Epoch : [19] Train loss : [0.0834785860318404] Val Score : [0.5193680391288173])\n","Epoch : [20] Train loss : [0.08250837486523849] Val Score : [0.5235333001820373])\n","Epoch : [21] Train loss : [0.07943584426091267] Val Score : [0.530850801902153])\n","Epoch : [22] Train loss : [0.07684543614204113] Val Score : [0.5378234758406146])\n","Epoch : [23] Train loss : [0.07357291934581903] Val Score : [0.5412036648612704])\n","Epoch : [24] Train loss : [0.0737088666512416] Val Score : [0.5414816272113812])\n","Epoch : [25] Train loss : [0.0747114156301205] Val Score : [0.547577683482964])\n","Epoch : [26] Train loss : [0.07574371248483658] Val Score : [0.5499639140767333])\n","Epoch : [27] Train loss : [0.07179589569568634] Val Score : [0.5516194348205763])\n","Epoch : [28] Train loss : [0.07082324475049973] Val Score : [0.5552115490246543])\n","Epoch : [29] Train loss : [0.06877401757698792] Val Score : [0.5594039699950464])\n","Epoch : [30] Train loss : [0.06969230622053146] Val Score : [0.5637930526328199])\n","Epoch : [31] Train loss : [0.06472177259050883] Val Score : [0.5677267124107939])\n","Epoch : [32] Train loss : [0.06488130098352066] Val Score : [0.5754877538881921])\n","Epoch : [33] Train loss : [0.06469856030665912] Val Score : [0.5759937907719419])\n","Epoch : [34] Train loss : [0.06597587781456801] Val Score : [0.5770244621487357])\n","Epoch : [35] Train loss : [0.06458517278616245] Val Score : [0.5866045319852622])\n","Epoch : [36] Train loss : [0.0627164737536357] Val Score : [0.5998969503086471])\n","Epoch : [37] Train loss : [0.061893909309919067] Val Score : [0.6137348919203808])\n","Epoch : [38] Train loss : [0.06097615968722563] Val Score : [0.6614216855893797])\n","Epoch : [39] Train loss : [0.06107931297559004] Val Score : [0.752094104263044])\n","Epoch : [40] Train loss : [0.06026168912649155] Val Score : [0.7973199624677456])\n","Epoch : [43] Train loss : [0.05749315883104618] Val Score : [0.8202665410912253])\n","Epoch : [45] Train loss : [0.05772115118228472] Val Score : [0.8287186884323108])\n","Epoch : [46] Train loss : [0.05999476634539091] Val Score : [0.8376267560436427])\n","Epoch : [47] Train loss : [0.05614733065550144] Val Score : [0.8470287373843977])\n","Epoch : [49] Train loss : [0.05589309764596132] Val Score : [0.8621517488551477])\n","Epoch : [50] Train loss : [0.05574975391993156] Val Score : [0.8674887641844412])\n","Epoch : [51] Train loss : [0.055479033635212824] Val Score : [0.890501890608512])\n","Epoch : [55] Train loss : [0.05251916784506578] Val Score : [0.9031202878275757])\n","Epoch : [60] Train loss : [0.052205754014161915] Val Score : [0.9097393418694286])\n","Epoch 00072: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch : [72] Train loss : [0.04367829801944586] Val Score : [0.9165787375726882])\n","Epoch 00084: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch 00095: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch 00106: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch 00117: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch 00128: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch 00139: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch 00150: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00161: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch 00172: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00183: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00194: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch 00205: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch 00216: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00227: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00238: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00249: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch 00260: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch 00271: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [0] Train loss : [0.46555615159181446] Val Score : [0.1362902927285818])\n","Epoch : [1] Train loss : [0.2575101050046774] Val Score : [0.4136146644740899])\n","Epoch : [2] Train loss : [0.18925241094369155] Val Score : [0.47185155805266155])\n","Epoch : [3] Train loss : [0.15874829659095177] Val Score : [0.4898340540089482])\n","Epoch : [4] Train loss : [0.14436318209538093] Val Score : [0.5008078628171415])\n","Epoch : [5] Train loss : [0.13565170306425828] Val Score : [0.5047499335938982])\n","Epoch : [6] Train loss : [0.12568108049722818] Val Score : [0.506937276930102])\n","Epoch : [7] Train loss : [0.1172097520186351] Val Score : [0.5089475732680023])\n","Epoch : [8] Train loss : [0.1143918834053553] Val Score : [0.5120750231779909])\n","Epoch : [9] Train loss : [0.10706997146973243] Val Score : [0.5140792843826814])\n","Epoch : [10] Train loss : [0.10290546944508186] Val Score : [0.5168151934986798])\n","Epoch : [11] Train loss : [0.10240219820004243] Val Score : [0.5203519891839795])\n","Epoch : [12] Train loss : [0.09389819319431598] Val Score : [0.5253008824887907])\n","Epoch : [13] Train loss : [0.09085103410940903] Val Score : [0.5299939251334721])\n","Epoch : [15] Train loss : [0.08777387382892463] Val Score : [0.5357840109763295])\n","Epoch : [16] Train loss : [0.08456070835773762] Val Score : [0.5404756665856641])\n","Epoch : [17] Train loss : [0.08119929696504886] Val Score : [0.5419510919830159])\n","Epoch : [18] Train loss : [0.07972536579920696] Val Score : [0.545687326564355])\n","Epoch : [19] Train loss : [0.07725018320175317] Val Score : [0.5498401144317107])\n","Epoch : [20] Train loss : [0.07602645686039558] Val Score : [0.5509723592989528])\n","Epoch : [21] Train loss : [0.07392043219162868] Val Score : [0.5520141028516564])\n","Epoch : [22] Train loss : [0.07277842209889339] Val Score : [0.5522799507755507])\n","Epoch : [23] Train loss : [0.07585546603569618] Val Score : [0.5530909538953747])\n","Epoch : [24] Train loss : [0.07200265274598049] Val Score : [0.5540635212673894])\n","Epoch : [25] Train loss : [0.07141273640669309] Val Score : [0.5544893606698819])\n","Epoch : [26] Train loss : [0.07083325145336297] Val Score : [0.555949787291009])\n","Epoch : [27] Train loss : [0.06792176113678859] Val Score : [0.5560994112813382])\n","Epoch : [29] Train loss : [0.07046809907142933] Val Score : [0.5579485464511985])\n","Epoch : [31] Train loss : [0.06812100456311153] Val Score : [0.5594039699950464])\n","Epoch : [32] Train loss : [0.0630203800705763] Val Score : [0.5612692094416567])\n","Epoch : [33] Train loss : [0.06658960191103128] Val Score : [0.5628713921901528])\n","Epoch : [34] Train loss : [0.06647272522632892] Val Score : [0.5643573637432558])\n","Epoch : [35] Train loss : [0.06199354105270826] Val Score : [0.5655124185105593])\n","Epoch : [36] Train loss : [0.06227905790393169] Val Score : [0.5696384775062183])\n","Epoch : [38] Train loss : [0.05964846335924589] Val Score : [0.5767644328126454])\n","Epoch : [39] Train loss : [0.0606648214161396] Val Score : [0.5783489094798163])\n","Epoch : [40] Train loss : [0.06174647148985129] Val Score : [0.6052147456627964])\n","Epoch : [41] Train loss : [0.059044930224235244] Val Score : [0.6199839985046101])\n","Epoch : [42] Train loss : [0.05920419010978479] Val Score : [0.7206844679680786])\n","Epoch : [43] Train loss : [0.061495895855701886] Val Score : [0.7470759905302604])\n","Epoch : [44] Train loss : [0.0582934758411004] Val Score : [0.7495600450513867])\n","Epoch : [45] Train loss : [0.057501027217278115] Val Score : [0.762761970120889])\n","Epoch : [51] Train loss : [0.05677484405728487] Val Score : [0.7655703273293624])\n","Epoch : [57] Train loss : [0.05366327498967831] Val Score : [0.7743645687973808])\n","Epoch : [60] Train loss : [0.05507313230862984] Val Score : [0.777425875747303])\n","Epoch : [61] Train loss : [0.0525141149186171] Val Score : [0.7870308296420961])\n","Epoch : [65] Train loss : [0.05087378305884508] Val Score : [0.7903809848799157])\n","Epoch : [66] Train loss : [0.05092834910521141] Val Score : [0.8045965667777433])\n","Epoch : [68] Train loss : [0.047948979414426364] Val Score : [0.8202665410912253])\n","Epoch : [70] Train loss : [0.04964828433898779] Val Score : [0.8287186884323108])\n","Epoch : [75] Train loss : [0.04716480093506666] Val Score : [0.8422634702634115])\n","Epoch : [77] Train loss : [0.04794329691391725] Val Score : [0.8470287373843977])\n","Epoch : [79] Train loss : [0.04763306935246174] Val Score : [0.8621517488551477])\n","Epoch : [80] Train loss : [0.047515242718733273] Val Score : [0.8674887641844412])\n","Epoch : [81] Train loss : [0.04358047304245142] Val Score : [0.872984830495149])\n","Epoch : [82] Train loss : [0.04565258553394905] Val Score : [0.8786471773914175])\n","Epoch : [83] Train loss : [0.04599894640537409] Val Score : [0.8844834793761085])\n","Epoch : [87] Train loss : [0.04633045454437916] Val Score : [0.890501890608512])\n","Epoch : [96] Train loss : [0.04657230239648085] Val Score : [0.9031202878275757])\n","Epoch : [107] Train loss : [0.044481897296813816] Val Score : [0.9097393418694286])\n","Epoch : [110] Train loss : [0.04074327246500896] Val Score : [0.9165787375726882])\n","Epoch 00122: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch 00133: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch 00144: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch 00155: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch 00166: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch 00177: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch 00188: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch 00199: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00210: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch 00221: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00232: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00243: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch 00254: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch 00265: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00276: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00287: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00298: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch : [0] Train loss : [0.48610814947348374] Val Score : [0.06451038760398584])\n","Epoch : [1] Train loss : [0.2784677308339339] Val Score : [0.37853293921706416])\n","Epoch : [2] Train loss : [0.19793744270618147] Val Score : [0.46003670019901594])\n","Epoch : [3] Train loss : [0.16491689246434432] Val Score : [0.48814773389121063])\n","Epoch : [4] Train loss : [0.14497344425091377] Val Score : [0.4998026953129782])\n","Epoch : [5] Train loss : [0.13331852738673872] Val Score : [0.5055686833488627])\n","Epoch : [6] Train loss : [0.1256506678003531] Val Score : [0.5066168817526187])\n","Epoch : [7] Train loss : [0.11809706000181344] Val Score : [0.5085277787480291])\n","Epoch : [8] Train loss : [0.11351179102292427] Val Score : [0.5098862369603736])\n","Epoch : [9] Train loss : [0.10770413909967129] Val Score : [0.5111594863962663])\n","Epoch : [10] Train loss : [0.10764617759447831] Val Score : [0.512188389781633])\n","Epoch : [11] Train loss : [0.10306345843351804] Val Score : [0.5123308526905349])\n","Epoch : [12] Train loss : [0.09918278054549144] Val Score : [0.5141717155467381])\n","Epoch : [13] Train loss : [0.09662008056273827] Val Score : [0.51531006027499])\n","Epoch : [14] Train loss : [0.09268446954397055] Val Score : [0.5169190613448337])\n","Epoch : [15] Train loss : [0.09064106242014812] Val Score : [0.518129695865073])\n","Epoch : [16] Train loss : [0.09181820601224899] Val Score : [0.5195227096067735])\n","Epoch : [17] Train loss : [0.08580116927623749] Val Score : [0.5213372477849859])\n","Epoch : [18] Train loss : [0.08129410846875264] Val Score : [0.5240922689568898])\n","Epoch : [19] Train loss : [0.07921199615185077] Val Score : [0.5277528171287835])\n","Epoch : [20] Train loss : [0.0794079853938176] Val Score : [0.531038314631336])\n","Epoch : [21] Train loss : [0.07950612616080505] Val Score : [0.5325243769086968])\n","Epoch : [22] Train loss : [0.0755131863630735] Val Score : [0.5334045484287037])\n","Epoch : [23] Train loss : [0.07314018675914177] Val Score : [0.5380691350460268])\n","Epoch : [24] Train loss : [0.06987306532951501] Val Score : [0.5398539540351446])\n","Epoch : [25] Train loss : [0.07210410271699612] Val Score : [0.5421410861959591])\n","Epoch : [26] Train loss : [0.07212914641086872] Val Score : [0.543607959163492])\n","Epoch : [27] Train loss : [0.07116705351150952] Val Score : [0.5474631286456717])\n","Epoch : [28] Train loss : [0.06957205155721077] Val Score : [0.5535042161494685])\n","Epoch : [29] Train loss : [0.06766899875723399] Val Score : [0.5556525296376691])\n","Epoch : [30] Train loss : [0.06930704357532355] Val Score : [0.5671099187640007])\n","Epoch : [31] Train loss : [0.06627578116380252] Val Score : [0.5834798371413035])\n","Epoch : [32] Train loss : [0.06310584453436044] Val Score : [0.5946809246376881])\n","Epoch : [33] Train loss : [0.06571086266866097] Val Score : [0.6552810760341061])\n","Epoch : [34] Train loss : [0.06387471952117406] Val Score : [0.730971061881369])\n","Epoch : [35] Train loss : [0.06318499291172394] Val Score : [0.7743645687973808])\n","Epoch : [36] Train loss : [0.0628640863757867] Val Score : [0.79380975986869])\n","Epoch : [44] Train loss : [0.05870521097229077] Val Score : [0.7973199624677456])\n","Epoch : [45] Train loss : [0.05586935608432843] Val Score : [0.8009145358549308])\n","Epoch : [46] Train loss : [0.05351083095257099] Val Score : [0.8045965667777433])\n","Epoch : [47] Train loss : [0.05443298816680908] Val Score : [0.8122361199071142])\n","Epoch : [48] Train loss : [0.05527912137600092] Val Score : [0.8202665410912253])\n","Epoch : [49] Train loss : [0.05683317207373106] Val Score : [0.8287186884323108])\n","Epoch : [52] Train loss : [0.05511597687235245] Val Score : [0.8376267560436427])\n","Epoch : [53] Train loss : [0.051007965149787754] Val Score : [0.8422634702634115])\n","Epoch : [57] Train loss : [0.05105526114885624] Val Score : [0.8519279892324237])\n","Epoch : [60] Train loss : [0.04942347739751522] Val Score : [0.8621517488551477])\n","Epoch : [61] Train loss : [0.0491135917030848] Val Score : [0.8844834793761085])\n","Epoch : [62] Train loss : [0.050498247433167234] Val Score : [0.8967110829723166])\n","Epoch : [63] Train loss : [0.04993041461476913] Val Score : [0.9097393418694286])\n","Epoch : [65] Train loss : [0.04987564625648352] Val Score : [0.9165787375726882])\n","Epoch 00077: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch 00088: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch 00099: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch 00110: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch 00121: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch 00132: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch 00143: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch 00154: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00165: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch 00176: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00187: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00198: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch 00209: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch 00220: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00231: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00242: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00253: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch 00264: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch 00275: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [0] Train loss : [0.4715359119268564] Val Score : [0.06866306800787375])\n","Epoch : [1] Train loss : [0.2650673951093967] Val Score : [0.40438987982332497])\n","Epoch : [2] Train loss : [0.19048281816335824] Val Score : [0.47916159383504936])\n","Epoch : [3] Train loss : [0.16054783876125628] Val Score : [0.4978622466206771])\n","Epoch : [4] Train loss : [0.14279560630138105] Val Score : [0.5024081773027991])\n","Epoch : [5] Train loss : [0.1343048237837278] Val Score : [0.505678267507586])\n","Epoch : [6] Train loss : [0.12465828313277318] Val Score : [0.5068224016293257])\n","Epoch : [7] Train loss : [0.1183750107884407] Val Score : [0.5091726782198059])\n","Epoch : [8] Train loss : [0.11295072906292401] Val Score : [0.5101984297367129])\n","Epoch : [9] Train loss : [0.10765006335882041] Val Score : [0.5117102166712415])\n","Epoch : [10] Train loss : [0.10708564519882202] Val Score : [0.5121033148745607])\n","Epoch : [11] Train loss : [0.10406909768397991] Val Score : [0.5135021076321727])\n","Epoch : [12] Train loss : [0.09825505774754745] Val Score : [0.5149244728922658])\n","Epoch : [13] Train loss : [0.09540505879200421] Val Score : [0.5162688904478031])\n","Epoch : [14] Train loss : [0.09283631237653586] Val Score : [0.5184609572505033])\n","Epoch : [15] Train loss : [0.09188165630285557] Val Score : [0.5210455680675096])\n","Epoch : [16] Train loss : [0.08814082352014688] Val Score : [0.5291075832574624])\n","Epoch : [17] Train loss : [0.08573254713645348] Val Score : [0.5318027135980778])\n","Epoch : [18] Train loss : [0.08601571676822808] Val Score : [0.5360114859479371])\n","Epoch : [19] Train loss : [0.08435836835549428] Val Score : [0.5367842009326989])\n","Epoch : [20] Train loss : [0.07891974999354436] Val Score : [0.5393319932844747])\n","Epoch : [21] Train loss : [0.07792573021008418] Val Score : [0.5440121239883796])\n","Epoch : [22] Train loss : [0.07676032472115296] Val Score : [0.5486285923988213])\n","Epoch : [23] Train loss : [0.07584547767272362] Val Score : [0.5525480217941127])\n","Epoch : [24] Train loss : [0.07531730429484294] Val Score : [0.5555048866039274])\n","Epoch : [25] Train loss : [0.07468230965045783] Val Score : [0.5597358408644433])\n","Epoch : [26] Train loss : [0.07320556044578552] Val Score : [0.5626898219704392])\n","Epoch : [27] Train loss : [0.07389959635642859] Val Score : [0.5747399991275138])\n","Epoch : [28] Train loss : [0.0710653679875227] Val Score : [0.5783489094798163])\n","Epoch : [29] Train loss : [0.0665984726869143] Val Score : [0.584088028027516])\n","Epoch : [30] Train loss : [0.06683742856750122] Val Score : [0.5853291805126263])\n","Epoch : [31] Train loss : [0.06848506973339961] Val Score : [0.5966253027265187])\n","Epoch : [32] Train loss : [0.06887290340203506] Val Score : [0.6159337810526528])\n","Epoch : [34] Train loss : [0.06763278406399947] Val Score : [0.6624915395103571])\n","Epoch : [35] Train loss : [0.06342473941353652] Val Score : [0.7470759905302604])\n","Epoch : [36] Train loss : [0.06474592708624326] Val Score : [0.752094104263044])\n","Epoch : [37] Train loss : [0.06536599793113194] Val Score : [0.7600119366040216])\n","Epoch : [41] Train loss : [0.05810517846391751] Val Score : [0.7655703273293624])\n","Epoch : [45] Train loss : [0.05941637347523983] Val Score : [0.7684388896488608])\n","Epoch : [46] Train loss : [0.05785661477309007] Val Score : [0.7743645687973808])\n","Epoch : [47] Train loss : [0.054690589698461384] Val Score : [0.7837566139258728])\n","Epoch : [48] Train loss : [0.055344716574137025] Val Score : [0.79380975986869])\n","Epoch : [53] Train loss : [0.05470519598860007] Val Score : [0.8122361199071142])\n","Epoch : [54] Train loss : [0.054917871665496096] Val Score : [0.8244378451249526])\n","Epoch : [56] Train loss : [0.05368850437494425] Val Score : [0.8287186884323108])\n","Epoch : [58] Train loss : [0.054228104650974274] Val Score : [0.8621517488551477])\n","Epoch : [59] Train loss : [0.053525411165677585] Val Score : [0.8674887641844412])\n","Epoch : [60] Train loss : [0.05041139400922335] Val Score : [0.8786471773914175])\n","Epoch : [61] Train loss : [0.04919137834356381] Val Score : [0.8844834793761085])\n","Epoch : [64] Train loss : [0.051621622477586455] Val Score : [0.9031202878275757])\n","Epoch : [68] Train loss : [0.04912173919952833] Val Score : [0.9097393418694286])\n","Epoch 00080: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch 00091: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch 00102: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch 00113: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch 00124: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch 00135: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch 00146: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch 00157: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00168: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch 00179: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00190: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00201: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch 00212: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch 00223: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00234: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00245: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00256: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch 00267: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch 00278: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [0] Train loss : [0.46529335471299976] Val Score : [0.11802315481556364])\n","Epoch : [1] Train loss : [0.25556903275159687] Val Score : [0.40863853951169227])\n","Epoch : [2] Train loss : [0.18887445674492762] Val Score : [0.47027059925397097])\n","Epoch : [3] Train loss : [0.16196367488457605] Val Score : [0.4878734978010977])\n","Epoch : [4] Train loss : [0.14413056465295646] Val Score : [0.49953387441310304])\n","Epoch : [5] Train loss : [0.1320799612081968] Val Score : [0.5048136919558095])\n","Epoch : [6] Train loss : [0.1251501853649433] Val Score : [0.5109156653338272])\n","Epoch : [7] Train loss : [0.11821485654665874] Val Score : [0.5164042751308315])\n","Epoch : [8] Train loss : [0.11082332065472236] Val Score : [0.5190237356460236])\n","Epoch : [9] Train loss : [0.10830696500264682] Val Score : [0.5219317359651965])\n","Epoch : [10] Train loss : [0.10328411310911179] Val Score : [0.522942312703837])\n","Epoch : [11] Train loss : [0.0998240073139851] Val Score : [0.5255501421253772])\n","Epoch : [12] Train loss : [0.09473816018838149] Val Score : [0.5262622048180549])\n","Epoch : [13] Train loss : [0.09267672839073035] Val Score : [0.5267840657920418])\n","Epoch : [14] Train loss : [0.08955962726703057] Val Score : [0.5279734532456781])\n","Epoch : [15] Train loss : [0.08644576141467461] Val Score : [0.5298140937214609])\n","Epoch : [16] Train loss : [0.08306709562356655] Val Score : [0.5307265707650914])\n","Epoch : [17] Train loss : [0.08189062774181366] Val Score : [0.5311011325592798])\n","Epoch : [18] Train loss : [0.07996372420054215] Val Score : [0.532391626391109])\n","Epoch : [19] Train loss : [0.0808734641625331] Val Score : [0.535260773313533])\n","Epoch : [20] Train loss : [0.07646767909710224] Val Score : [0.5357840109763295])\n","Epoch : [21] Train loss : [0.07647645358855908] Val Score : [0.5409284341917169])\n","Epoch : [22] Train loss : [0.0761820341532047] Val Score : [0.541668475427458])\n","Epoch : [23] Train loss : [0.07280588723145999] Val Score : [0.5441140534215738])\n","Epoch : [24] Train loss : [0.07394551428464743] Val Score : [0.5468967903812862])\n","Epoch : [25] Train loss : [0.07293122089826144] Val Score : [0.5480402825299603])\n","Epoch : [27] Train loss : [0.0686042162661369] Val Score : [0.5481570408842169])\n","Epoch : [28] Train loss : [0.06928870597710976] Val Score : [0.5518820033025613])\n","Epoch : [29] Train loss : [0.07132104325752991] Val Score : [0.5530909538953747])\n","Epoch : [30] Train loss : [0.07071677824625602] Val Score : [0.5556525296376691])\n","Epoch : [31] Train loss : [0.06754486835919894] Val Score : [0.555800828312292])\n","Epoch : [32] Train loss : [0.06565946225936596] Val Score : [0.5584269155630615])\n","Epoch : [34] Train loss : [0.06351937496891388] Val Score : [0.5595695120153324])\n","Epoch : [43] Train loss : [0.05800833266514998] Val Score : [0.5597358408644433])\n","Epoch : [44] Train loss : [0.05877200686014616] Val Score : [0.5641682994348549])\n","Epoch : [48] Train loss : [0.05852942971082834] Val Score : [0.5645473990169181])\n","Epoch : [50] Train loss : [0.058218054759960905] Val Score : [0.5665029305934602])\n","Epoch : [52] Train loss : [0.05548820644617081] Val Score : [0.5707423392713572])\n","Epoch : [53] Train loss : [0.057086721349221006] Val Score : [0.5732838152882681])\n","Epoch : [54] Train loss : [0.05281168566300319] Val Score : [0.5862824086461611])\n","Epoch : [55] Train loss : [0.05465465096326975] Val Score : [0.5903004521016563])\n","Epoch : [56] Train loss : [0.05341034726454662] Val Score : [0.6052147456627964])\n","Epoch : [57] Train loss : [0.05261189805773588] Val Score : [0.6844368008149726])\n","Epoch : [58] Train loss : [0.05381060907473931] Val Score : [0.8376267560436427])\n","Epoch : [59] Train loss : [0.05120088188694073] Val Score : [0.8470287373843977])\n","Epoch : [60] Train loss : [0.052252320716014274] Val Score : [0.8674887641844412])\n","Epoch : [61] Train loss : [0.05105246746769318] Val Score : [0.8786471773914175])\n","Epoch : [62] Train loss : [0.050779833816565] Val Score : [0.890501890608512])\n","Epoch : [64] Train loss : [0.04996884442292727] Val Score : [0.9031202878275757])\n","Epoch : [65] Train loss : [0.050794793149599664] Val Score : [0.9097393418694286])\n","Epoch 00077: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch : [86] Train loss : [0.03815030363889841] Val Score : [0.9165787375726882])\n","Epoch 00098: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch 00109: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch 00120: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch 00131: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch 00142: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch 00153: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch 00164: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00175: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch 00186: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00197: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00208: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch 00219: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch 00230: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00241: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00252: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00263: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch 00274: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch 00285: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [0] Train loss : [0.46724692445534927] Val Score : [0.11803408213828517])\n","Epoch : [1] Train loss : [0.2619685140939859] Val Score : [0.4008024306888872])\n","Epoch : [2] Train loss : [0.18922800398789918] Val Score : [0.47210019910856665])\n","Epoch : [3] Train loss : [0.15770299044939187] Val Score : [0.494513706345717])\n","Epoch : [4] Train loss : [0.13873940935501686] Val Score : [0.5051993707152821])\n","Epoch : [5] Train loss : [0.1294262821857746] Val Score : [0.5096034709243781])\n","Epoch : [6] Train loss : [0.12041225341650155] Val Score : [0.5151486303989417])\n","Epoch : [7] Train loss : [0.11461596477490205] Val Score : [0.5172686603946239])\n","Epoch : [8] Train loss : [0.10947312987767734] Val Score : [0.5223220205565594])\n","Epoch : [9] Train loss : [0.10444490898113984] Val Score : [0.5258527246831002])\n","Epoch : [10] Train loss : [0.10115802861177005] Val Score : [0.5280289262871035])\n","Epoch : [11] Train loss : [0.09505528612778737] Val Score : [0.5329945392318816])\n","Epoch : [12] Train loss : [0.09753764821932866] Val Score : [0.5368627250477384])\n","Epoch : [13] Train loss : [0.09551160610639133] Val Score : [0.5402075057997111])\n","Epoch : [14] Train loss : [0.09022660094958085] Val Score : [0.5493497907415081])\n","Epoch : [15] Train loss : [0.08564277566396274] Val Score : [0.5553578945916403])\n","Epoch : [16] Train loss : [0.08254084678796622] Val Score : [0.5589120063106608])\n","Epoch : [17] Train loss : [0.08036138002689068] Val Score : [0.5694213680073557])\n","Epoch : [18] Train loss : [0.08500941155048516] Val Score : [0.5762491119793732])\n","Epoch : [19] Train loss : [0.0775726643892435] Val Score : [0.6324825145461953])\n","Epoch : [20] Train loss : [0.07587762291614826] Val Score : [0.697743660770528])\n","Epoch : [21] Train loss : [0.07281816292267579] Val Score : [0.714936337281296])\n","Epoch : [22] Train loss : [0.07202867189278969] Val Score : [0.730971061881369])\n","Epoch : [25] Train loss : [0.07014787254425195] Val Score : [0.7331432493795871])\n","Epoch : [28] Train loss : [0.07053779696042721] Val Score : [0.7470759905302604])\n","Epoch : [34] Train loss : [0.06331987220507401] Val Score : [0.75467969893057])\n","Epoch : [35] Train loss : [0.06641736483344665] Val Score : [0.7600119366040216])\n","Epoch : [40] Train loss : [0.05819565888780814] Val Score : [0.7655703273293624])\n","Epoch : [44] Train loss : [0.05742489546537399] Val Score : [0.777425875747303])\n","Epoch : [47] Train loss : [0.05719423179443066] Val Score : [0.7903809848799157])\n","Epoch : [48] Train loss : [0.05611968842836527] Val Score : [0.808369294415656])\n","Epoch : [49] Train loss : [0.05711224847115003] Val Score : [0.8122361199071142])\n","Epoch : [51] Train loss : [0.05688348183265099] Val Score : [0.8162006166001039])\n","Epoch : [52] Train loss : [0.05401037604762958] Val Score : [0.8244378451249526])\n","Epoch : [53] Train loss : [0.053557658997865826] Val Score : [0.8287186884323108])\n","Epoch : [56] Train loss : [0.05465499454965958] Val Score : [0.8376267560436427])\n","Epoch : [57] Train loss : [0.053001475448791795] Val Score : [0.8422634702634115])\n","Epoch : [61] Train loss : [0.053733085783628315] Val Score : [0.8621517488551477])\n","Epoch : [67] Train loss : [0.05027207273703355] Val Score : [0.8674887641844412])\n","Epoch : [68] Train loss : [0.052907454852874465] Val Score : [0.8786471773914175])\n","Epoch : [69] Train loss : [0.05336894868658139] Val Score : [0.8844834793761085])\n","Epoch : [71] Train loss : [0.04784716837681257] Val Score : [0.890501890608512])\n","Epoch : [72] Train loss : [0.049400979796281226] Val Score : [0.8967110829723166])\n","Epoch : [79] Train loss : [0.04896449383634787] Val Score : [0.9031202878275757])\n","Epoch : [80] Train loss : [0.046592138421077] Val Score : [0.9097393418694286])\n","Epoch : [83] Train loss : [0.045787388602128394] Val Score : [0.9165787375726882])\n","Epoch 00095: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch 00106: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch 00117: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch 00128: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch 00139: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch 00150: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch 00161: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch 00172: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00183: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch 00194: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00205: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00216: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch 00227: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch 00238: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00249: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00260: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00271: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch 00282: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch 00293: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [0] Train loss : [0.47006770280691296] Val Score : [0.1084126452004469])\n","Epoch : [1] Train loss : [0.2636039543610353] Val Score : [0.39849899851571197])\n","Epoch : [2] Train loss : [0.18808368421517885] Val Score : [0.47426672024906585])\n","Epoch : [3] Train loss : [0.15737091234097114] Val Score : [0.492294755839185])\n","Epoch : [4] Train loss : [0.14128755033016205] Val Score : [0.5023495456120468])\n","Epoch : [5] Train loss : [0.1304671368919886] Val Score : [0.5065714272906093])\n","Epoch : [6] Train loss : [0.12180585356859061] Val Score : [0.5090723827203041])\n","Epoch : [7] Train loss : [0.11664713632601958] Val Score : [0.5105411530694601])\n","Epoch : [8] Train loss : [0.11028305383828971] Val Score : [0.5122452737883424])\n","Epoch : [9] Train loss : [0.10679474129126622] Val Score : [0.5244245316498689])\n","Epoch : [10] Train loss : [0.1038944165293987] Val Score : [0.541388666792193])\n","Epoch : [11] Train loss : [0.09770076378033711] Val Score : [0.5486285923988213])\n","Epoch : [12] Train loss : [0.09547456812400085] Val Score : [0.5626898219704392])\n","Epoch : [13] Train loss : [0.09357355191157414] Val Score : [0.6047512688678767])\n","Epoch : [14] Train loss : [0.08867694552128132] Val Score : [0.7130854976190938])\n","Epoch : [16] Train loss : [0.08120701347406094] Val Score : [0.7246883762645999])\n","Epoch : [18] Train loss : [0.07829598910533465] Val Score : [0.7267446884090669])\n","Epoch : [21] Train loss : [0.07295684401805584] Val Score : [0.7331432493795871])\n","Epoch : [22] Train loss : [0.07281623436854436] Val Score : [0.7353562550268086])\n","Epoch : [24] Train loss : [0.06875210713881713] Val Score : [0.7399094305905288])\n","Epoch : [26] Train loss : [0.0681511633671247] Val Score : [0.7470759905302604])\n","Epoch : [28] Train loss : [0.06555505498097493] Val Score : [0.752094104263044])\n","Epoch : [30] Train loss : [0.06432470564658825] Val Score : [0.7573184229436457])\n","Epoch : [33] Train loss : [0.0634860576918492] Val Score : [0.762761970120889])\n","Epoch : [34] Train loss : [0.06129829298991423] Val Score : [0.7655703273293624])\n","Epoch : [36] Train loss : [0.06214843231898088] Val Score : [0.7743645687973808])\n","Epoch : [45] Train loss : [0.05844087554858281] Val Score : [0.777425875747303])\n","Epoch : [51] Train loss : [0.05335788428783417] Val Score : [0.7837566139258728])\n","Epoch : [54] Train loss : [0.05403139814734459] Val Score : [0.7870308296420961])\n","Epoch : [55] Train loss : [0.05449606564182501] Val Score : [0.8009145358549308])\n","Epoch : [57] Train loss : [0.05078857220136202] Val Score : [0.8045965667777433])\n","Epoch : [58] Train loss : [0.05276744268261469] Val Score : [0.8162006166001039])\n","Epoch : [61] Train loss : [0.04950065165758133] Val Score : [0.8287186884323108])\n","Epoch : [63] Train loss : [0.05251294661026735] Val Score : [0.8621517488551477])\n","Epoch : [65] Train loss : [0.04872020821158703] Val Score : [0.8674887641844412])\n","Epoch : [66] Train loss : [0.052483514237862364] Val Score : [0.872984830495149])\n","Epoch : [68] Train loss : [0.04875081548323998] Val Score : [0.8844834793761085])\n","Epoch : [69] Train loss : [0.04546002155313125] Val Score : [0.890501890608512])\n","Epoch : [77] Train loss : [0.0460457753103513] Val Score : [0.8967110829723166])\n","Epoch : [81] Train loss : [0.04757527319284586] Val Score : [0.9031202878275757])\n","Epoch : [92] Train loss : [0.04432167112827301] Val Score : [0.9097393418694286])\n","Epoch 00104: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch 00115: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch 00126: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch 00137: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch 00148: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch 00159: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch 00170: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch 00181: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch 00192: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch 00203: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch 00214: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch 00225: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch 00236: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch 00247: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch 00258: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch 00269: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch 00280: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch 00291: reducing learning rate of group 0 to 3.8147e-08.\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"lxC8m58cyjgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#---# For test #---#\n","test_df = pd.read_csv('./test.csv')\n","test_df = test_df.drop(columns=['ID'])\n","test_dataset = MyDataset(test_df, False)\n","test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=6)\n","\n","model_preds = []\n","for i in range(config.K):\n","  model = AutoEncoder()\n","  model.load_state_dict(torch.load(f'./best_model{(i+1)}.pth'))\n","  model = nn.DataParallel(model)\n","  model.eval()\n","  preds = prediction(model, 0.97, test_loader, device)\n","  model_preds.append(preds)\n","\n","model_pred_df = pd.DataFrame(model_preds).transpose()\n","row_sum = model_pred_df.sum(axis=1)\n","pred = np.where(row_sum > 7, 1, 0) # 클수록 anomaly"],"metadata":{"id":"Y5lHDpl11Olc","executionInfo":{"status":"ok","timestamp":1659503026915,"user_tz":-540,"elapsed":20392,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"01c745ca-d131-48c8-f3be-8b1f16b891be"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["#---# For submission #---#\n","submit = pd.read_csv('./sample_submission.csv')\n","submit['Class'] = pred\n","submit.to_csv('./submit_autoencoder_with_vote_220803(2)_.csv', index=False)"],"metadata":{"id":"IgdZWXD0IJkR","executionInfo":{"status":"ok","timestamp":1659503054494,"user_tz":-540,"elapsed":643,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# from mpl_toolkits.mplot3d import Axes3D\n","# import matplotlib.pyplot as plt\n","# %matplotlib notebook\n","# fig = plt.figure()\n","# ax = fig.add_subplot(111, projection='3d')\n","# ax.scatter(test_z[:,1],test_z[:,0], test_z[:,2], c=test_labels.astype(int))\n","# ax.set_xlabel('Encoded')\n","# ax.set_ylabel('Euclidean')\n","# ax.set_zlabel('Cosine')\n","# plt.show()"],"metadata":{"id":"mSenGm1oJFWH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sum(pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJbfamFzc-MS","executionInfo":{"status":"ok","timestamp":1659492366029,"user_tz":-540,"elapsed":15,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"57f17de0-2d41-447b-d51f-37fed4fdb6ce"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["342"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":[""],"metadata":{"id":"gf_3CQ3Pc_D5"},"execution_count":null,"outputs":[]}]}