{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AutoEncoder+bootstrap+vote+clean.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1GtDfKW90iDn_irx9Ij7ckkNpI2VtLWvQ","authorship_tag":"ABX9TyN4psEjD8iHjVddzEvkLPcu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","# drive.mount('/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data')\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/IITP/sohyun/creditcard_prediction/data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aoTfHzuB_M7u","executionInfo":{"status":"ok","timestamp":1659575495094,"user_tz":-540,"elapsed":2464,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"81e0aaf2-4f47-4e8a-9547-522688dea1e6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data\n"]}]},{"cell_type":"code","source":["!pip install wandb -qqq\n","import wandb\n","wandb.login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pyCrbam-X2js","executionInfo":{"status":"ok","timestamp":1659575508259,"user_tz":-540,"elapsed":10691,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"1dbee6a1-4e1a-40db-ab01-c2caedfb81af"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msohyun\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"gPauNGcl-kic","executionInfo":{"status":"ok","timestamp":1659575512926,"user_tz":-540,"elapsed":1409,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"outputs":[],"source":["import random\n","import pandas as pd\n","import numpy as np\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","# wandb.init(project=\"\") # wandb init\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","source":["class MyDataset(Dataset):\n","    def __init__(self, df, eval_mode):\n","        self.df = df\n","        self.eval_mode = eval_mode\n","        if self.eval_mode:\n","            self.labels = self.df['Class'].values\n","            self.df = self.df.drop(columns=['Class']).values\n","        else:\n","            self.df = self.df.values\n","        \n","    def __getitem__(self, index):\n","        if self.eval_mode:\n","            self.x = self.df[index]\n","            self.y = self.labels[index]\n","            return torch.Tensor(self.x), self.y\n","        else:\n","            self.x = self.df[index]\n","            return torch.Tensor(self.x)\n","        \n","    def __len__(self):\n","        return len(self.df)\n","\n","class AutoEncoder(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","        self.Encoder = nn.Sequential(\n","            nn.Linear(30,64),\n","            nn.BatchNorm1d(64),\n","            nn.LeakyReLU(),\n","            nn.Linear(64,128),\n","            nn.BatchNorm1d(128),\n","            nn.LeakyReLU(),\n","        )\n","        self.Decoder = nn.Sequential(\n","            nn.Linear(128,64),\n","            nn.BatchNorm1d(64),\n","            nn.LeakyReLU(),\n","            nn.Linear(64,30),\n","        )\n","        \n","    def forward(self, x):\n","        x = self.Encoder(x)\n","        x = self.Decoder(x)\n","        return x\n","\n","class Trainer():\n","    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.scheduler = scheduler\n","        self.device = device\n","        # Loss Function\n","        self.criterion = nn.L1Loss().to(self.device)\n","        \n","    def fit(self, config, modelNum=None):\n","        self.model.to(self.device)\n","        best_score = 0\n","        for epoch in range(config.EPOCHS):\n","            self.model.train()\n","            train_loss = []\n","            for x in iter(self.train_loader):\n","                x = x.float().to(self.device)\n","                self.optimizer.zero_grad()\n","\n","                _x = self.model(x)\n","                loss = self.criterion(x, _x)\n","\n","                loss.backward()\n","                self.optimizer.step()\n","\n","                train_loss.append(loss.item())\n","\n","            score = self.validation(self.model, config.thr)\n","            # print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n","            \n","            wandb.log({\n","                \"validation f1\": score,\n","                \"loss\": loss\n","            })\n","            if self.scheduler is not None:\n","              self.scheduler.step(score)\n","\n","            if best_score < score:\n","              print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n","              best_score = score\n","              if modelNum :\n","                torch.save(self.model.module.state_dict(), f'./best_model{modelNum}.pth', _use_new_zipfile_serialization=False)\n","              else :\n","                torch.save(self.model.module.state_dict(), f'./best_model.pth', _use_new_zipfile_serialization=False)\n","  \n","    def validation(self, eval_model, thr):\n","        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","        eval_model.eval()\n","        pred = []\n","        true = []\n","        with torch.no_grad():\n","            for x, y in iter(self.val_loader):\n","                x = x.float().to(self.device)\n","\n","                _x = self.model(x)\n","                diff = cos(x, _x).cpu().tolist()\n","                batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n","                pred += batch_pred\n","                true += y.tolist()\n","\n","        return f1_score(true, pred, average='macro')"],"metadata":{"id":"kijk5u73jo-B","executionInfo":{"status":"ok","timestamp":1659575515681,"user_tz":-540,"elapsed":506,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def prediction(model, thr, test_loader, device):\n","  model.to(device)\n","  model.eval()\n","  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","  pred = []\n","  with torch.no_grad():\n","    for x in iter(test_loader):\n","      x = x.float().to(device)\n","      \n","      _x = model(x)\n","      \n","      diff = cos(x, _x).cpu().tolist()\n","      batch_pred = np.where(np.array(diff)<thr, 1, 0).tolist()\n","      pred += batch_pred\n","  return pred"],"metadata":{"id":"z2KhkzS2QK_r","executionInfo":{"status":"ok","timestamp":1659575518203,"user_tz":-540,"elapsed":368,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def main(config):\n","  seed_everything(config.SEED) # Seed fix\n","\n","  #---# DATA #---#\n","  train_df = pd.read_csv('./train.csv')\n","  train_df = train_df.drop(columns=['ID'])\n","  val_df = pd.read_csv('./val.csv')\n","  val_df = val_df.drop(columns=['ID'])\n","  test_df = pd.read_csv('./test.csv')\n","  test_df = test_df.drop(columns=['ID'])\n","  models = [] # list of models\n","\n","  val_dataset = MyDataset(df = val_df, eval_mode=True)\n","  val_loader = DataLoader(val_dataset, batch_size=config.BS, shuffle=False)\n","  test_dataset = MyDataset(test_df, False)\n","  test_loader = DataLoader(test_dataset, batch_size=config.BS, shuffle=False, num_workers=6)\n","\n","  # for refine\n","  train_dataset = MyDataset(df=train_df, eval_mode=False)\n","  train_loader = DataLoader(train_dataset, batch_size=config.BS, shuffle=True)\n","  model = nn.DataParallel(AutoEncoder())\n","  model.eval()\n","  optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-2)\n","  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, threshold_mode='abs', min_lr=1e-8, verbose=True)\n","  \n","  trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n","  trainer.fit(config)\n","\n","  model = AutoEncoder()\n","  model.load_state_dict(torch.load(f'./best_model.pth'))\n","  model = nn.DataParallel(model)\n","  model.eval()\n","  preds = prediction(model, config.thr, train_loader, device)\n","  print(\"<<<없애는 anomay 수>>> \", sum(preds))\n","  train_df_pseudo = train_df\n","  train_df_pseudo['Class'] = preds\n","  \n","  idx_anomal = train_df_pseudo[train_df_pseudo['Class'] == 1].index\n","  train_df_pseudo = train_df_pseudo.drop(idx_anomal)\n","  train_df_pseudo = train_df_pseudo.drop(columns=['Class'])\n","  train_df_pseudo = train_df_pseudo.reset_index(drop=True)\n","\n","  # for ensemble\n","  for i in range(config.K):\n","    choose_idx = np.random.choice(train_df_pseudo.shape[0], 50000, replace=True)\n","    train_df_choose = train_df_pseudo.loc[choose_idx,:]\n","    train_dataset = MyDataset(df=train_df_choose, eval_mode=False)\n","    train_loader = DataLoader(train_dataset, batch_size=config.BS, shuffle=True)\n","\n","    model = nn.DataParallel(AutoEncoder())\n","    model.eval()\n","    optimizer = torch.optim.Adam(params = model.parameters(), lr = config.LR)\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, threshold_mode='abs', min_lr=1e-8, verbose=True)\n","\n","    trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n","    trainer.fit(config, modelNum=(i+1))\n","\n","    models.append(model)\n","\n","  # # for test\n","  # model_preds = []\n","  # for i in range(config.K):\n","  #   model = AutoEncoder()\n","  #   model.load_state_dict(torch.load(f'./best_model{(i+1)}.pth'))\n","  #   model = nn.DataParallel(model)\n","  #   model.eval()\n","  #   preds = prediction(model, 0.97, test_loader, device)\n","  #   model_preds.append(preds)\n","\n","  # model_pred_df = pd.DataFrame(model_preds).transpose()\n","  # row_sum = model_pred_df.sum(axis=1)\n","  # pred = np.where(row_sum > 3, 1, 0) # 클수록 anomaly\n","  \n","  # return pred\n","\n","if __name__ == '__main__':\n","  wandb.init()\n","  import easydict\n","  args = easydict.EasyDict({\n","      \"K\" : 10,\n","      \"EPOCHS\" : 200, #65 ## 400\n","      \"LR\" : 1e-2,\n","      \"BS\" : 16384, #16384\n","      \"SEED\" : 1004,\n","      \"thr\" : 0.95\n","  })\n","  config = args\n","\n","  print('------------ Options -------------')\n","  for k, v in sorted(args.items()):\n","    print('%s: %s' % (str(k), str(v)))\n","  print('-------------- End ----------------')\n","\n","  pred = main(config)"],"metadata":{"id":"MOLXoEwK8TqY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"lxC8m58cyjgc","executionInfo":{"status":"ok","timestamp":1659577299799,"user_tz":-540,"elapsed":361,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"pWG8Q-E7Qeqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import easydict\n","args = easydict.EasyDict({\n","    \"K\" : 10,\n","    \"EPOCHS\" : 200, #65 ## 400\n","    \"LR\" : 1e-2,\n","    \"BS\" : 16384, #16384\n","    \"SEED\" : 1004,\n","    \"thr\" : 0.95\n","})\n","config = args\n","\n","#---# For test #---#\n","test_df = pd.read_csv('./test.csv')\n","test_df = test_df.drop(columns=['ID'])\n","test_dataset = MyDataset(test_df, False)\n","test_loader = DataLoader(test_dataset, batch_size=config.BS, shuffle=False, num_workers=6)\n","\n","model_preds = []\n","for i in range(config.K):\n","  model = AutoEncoder()\n","  model.load_state_dict(torch.load(f'./best_model{(i+1)}.pth'))\n","  model = nn.DataParallel(model)\n","  model.eval()\n","  preds = prediction(model, config.thr, test_loader, device)\n","  model_preds.append(preds)\n","\n","model_pred_df = pd.DataFrame(model_preds).transpose()\n","row_sum = model_pred_df.sum(axis=1)\n","pred = np.where(row_sum > 7, 1, 0) # 클수록 anomaly"],"metadata":{"id":"Y5lHDpl11Olc","executionInfo":{"status":"ok","timestamp":1659577007668,"user_tz":-540,"elapsed":11948,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba80fc18-7503-4e52-c942-c3f76b4d1ba5"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["#---# For submission #---#\n","submit = pd.read_csv('./sample_submission.csv')\n","submit['Class'] = pred\n","submit.to_csv('./submit_autoencoder_with_vote_clean_10000.csv', index=False)"],"metadata":{"id":"IgdZWXD0IJkR","executionInfo":{"status":"ok","timestamp":1659577018333,"user_tz":-540,"elapsed":1540,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# from mpl_toolkits.mplot3d import Axes3D\n","# import matplotlib.pyplot as plt\n","# %matplotlib notebook\n","# fig = plt.figure()\n","# ax = fig.add_subplot(111, projection='3d')\n","# ax.scatter(test_z[:,1],test_z[:,0], test_z[:,2], c=test_labels.astype(int))\n","# ax.set_xlabel('Encoded')\n","# ax.set_ylabel('Euclidean')\n","# ax.set_zlabel('Cosine')\n","# plt.show()"],"metadata":{"id":"mSenGm1oJFWH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sum(pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJbfamFzc-MS","executionInfo":{"status":"ok","timestamp":1659516214389,"user_tz":-540,"elapsed":724,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"aec68f39-7b8e-4d24-ddb2-d1adf01b5b6e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["338"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["train_df = pd.read_csv('./train.csv')\n","train_df = train_df.drop(columns=['ID'])\n","val_df = pd.read_csv('./val.csv')\n","val_df = val_df.drop(columns=['ID'])"],"metadata":{"id":"gf_3CQ3Pc_D5","executionInfo":{"status":"ok","timestamp":1659578368502,"user_tz":-540,"elapsed":1933,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_df"],"metadata":{"id":"GLPbonRMlDbB","executionInfo":{"status":"ok","timestamp":1659578372169,"user_tz":-540,"elapsed":413,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"60832183-7b3c-44f9-be96-4a6d5c46c5e0","colab":{"base_uri":"https://localhost:8080/","height":488}},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               V1         V2        V3        V4        V5        V6  \\\n","0       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n","1       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n","2       -0.425966   0.960523  1.141109 -0.168252  0.420987 -0.029728   \n","3       -0.644269   1.417964  1.074380 -0.492199  0.948934  0.428118   \n","4       -0.894286   0.286157 -0.113192 -0.271526  2.669599  3.721818   \n","...           ...        ...       ...       ...       ...       ...   \n","113837 -12.516732  10.187818 -8.476671 -2.510473 -4.586669 -1.394465   \n","113838   1.884849  -0.143540 -0.999943  1.506772 -0.035300 -0.613638   \n","113839  -0.241923   0.712247  0.399806 -0.463406  0.244531 -1.343668   \n","113840   0.120316   0.931005 -0.546012 -0.745097  1.130314 -0.235973   \n","113841 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n","\n","              V7        V8        V9       V10  ...       V21       V22  \\\n","0       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n","1       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n","2       0.476201  0.260314 -0.568671 -0.371407  ... -0.208254 -0.559825   \n","3       1.120631 -3.807864  0.615375  1.249376  ...  1.943465 -1.015455   \n","4       0.370145  0.851084 -0.392048 -0.410430  ... -0.073425 -0.268092   \n","...          ...       ...       ...       ...  ...       ...       ...   \n","113837 -3.632516  5.498583  4.893089  8.655320  ... -0.944759 -1.565026   \n","113838  0.190241 -0.249058  0.666458  0.120908  ...  0.144008  0.634646   \n","113839  0.929369 -0.206210  0.106234 -0.284708  ... -0.228876 -0.514376   \n","113840  0.812722  0.115093 -0.204064 -0.657422  ... -0.314205 -0.808520   \n","113841 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n","\n","             V23       V24       V25       V26       V27       V28       V29  \\\n","0       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  4.983721   \n","1      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  1.418291   \n","2      -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080 -0.256131   \n","3       0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339  0.262698   \n","4      -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404  0.994900   \n","...          ...       ...       ...       ...       ...       ...       ...   \n","113837  0.890675 -1.253276  1.786717  0.320763  2.090712  1.232864 -0.169496   \n","113838 -0.042114 -0.053206  0.316403 -0.461441  0.018265 -0.041068  0.530986   \n","113839  0.279598  0.371441 -0.559238  0.113144  0.131507  0.081265 -0.230699   \n","113840  0.050343  0.102800 -0.435870  0.124079  0.217940  0.068803 -0.269825   \n","113841  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731 -0.296653   \n","\n","             V30  \n","0      -0.994972  \n","1      -0.994972  \n","2      -0.994960  \n","3      -0.994901  \n","4      -0.994901  \n","...          ...  \n","113837  1.034857  \n","113838  1.034881  \n","113839  1.034904  \n","113840  1.034939  \n","113841  1.034951  \n","\n","[113842 rows x 30 columns]"],"text/html":["\n","  <div id=\"df-dcf5e24a-0344-476d-8d15-d65acc6cb6ab\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>V10</th>\n","      <th>...</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>V29</th>\n","      <th>V30</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1.358354</td>\n","      <td>-1.340163</td>\n","      <td>1.773209</td>\n","      <td>0.379780</td>\n","      <td>-0.503198</td>\n","      <td>1.800499</td>\n","      <td>0.791461</td>\n","      <td>0.247676</td>\n","      <td>-1.514654</td>\n","      <td>0.207643</td>\n","      <td>...</td>\n","      <td>0.247998</td>\n","      <td>0.771679</td>\n","      <td>0.909412</td>\n","      <td>-0.689281</td>\n","      <td>-0.327642</td>\n","      <td>-0.139097</td>\n","      <td>-0.055353</td>\n","      <td>-0.059752</td>\n","      <td>4.983721</td>\n","      <td>-0.994972</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.966272</td>\n","      <td>-0.185226</td>\n","      <td>1.792993</td>\n","      <td>-0.863291</td>\n","      <td>-0.010309</td>\n","      <td>1.247203</td>\n","      <td>0.237609</td>\n","      <td>0.377436</td>\n","      <td>-1.387024</td>\n","      <td>-0.054952</td>\n","      <td>...</td>\n","      <td>-0.108300</td>\n","      <td>0.005274</td>\n","      <td>-0.190321</td>\n","      <td>-1.175575</td>\n","      <td>0.647376</td>\n","      <td>-0.221929</td>\n","      <td>0.062723</td>\n","      <td>0.061458</td>\n","      <td>1.418291</td>\n","      <td>-0.994972</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.425966</td>\n","      <td>0.960523</td>\n","      <td>1.141109</td>\n","      <td>-0.168252</td>\n","      <td>0.420987</td>\n","      <td>-0.029728</td>\n","      <td>0.476201</td>\n","      <td>0.260314</td>\n","      <td>-0.568671</td>\n","      <td>-0.371407</td>\n","      <td>...</td>\n","      <td>-0.208254</td>\n","      <td>-0.559825</td>\n","      <td>-0.026398</td>\n","      <td>-0.371427</td>\n","      <td>-0.232794</td>\n","      <td>0.105915</td>\n","      <td>0.253844</td>\n","      <td>0.081080</td>\n","      <td>-0.256131</td>\n","      <td>-0.994960</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.644269</td>\n","      <td>1.417964</td>\n","      <td>1.074380</td>\n","      <td>-0.492199</td>\n","      <td>0.948934</td>\n","      <td>0.428118</td>\n","      <td>1.120631</td>\n","      <td>-3.807864</td>\n","      <td>0.615375</td>\n","      <td>1.249376</td>\n","      <td>...</td>\n","      <td>1.943465</td>\n","      <td>-1.015455</td>\n","      <td>0.057504</td>\n","      <td>-0.649709</td>\n","      <td>-0.415267</td>\n","      <td>-0.051634</td>\n","      <td>-1.206921</td>\n","      <td>-1.085339</td>\n","      <td>0.262698</td>\n","      <td>-0.994901</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.894286</td>\n","      <td>0.286157</td>\n","      <td>-0.113192</td>\n","      <td>-0.271526</td>\n","      <td>2.669599</td>\n","      <td>3.721818</td>\n","      <td>0.370145</td>\n","      <td>0.851084</td>\n","      <td>-0.392048</td>\n","      <td>-0.410430</td>\n","      <td>...</td>\n","      <td>-0.073425</td>\n","      <td>-0.268092</td>\n","      <td>-0.204233</td>\n","      <td>1.011592</td>\n","      <td>0.373205</td>\n","      <td>-0.384157</td>\n","      <td>0.011747</td>\n","      <td>0.142404</td>\n","      <td>0.994900</td>\n","      <td>-0.994901</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>113837</th>\n","      <td>-12.516732</td>\n","      <td>10.187818</td>\n","      <td>-8.476671</td>\n","      <td>-2.510473</td>\n","      <td>-4.586669</td>\n","      <td>-1.394465</td>\n","      <td>-3.632516</td>\n","      <td>5.498583</td>\n","      <td>4.893089</td>\n","      <td>8.655320</td>\n","      <td>...</td>\n","      <td>-0.944759</td>\n","      <td>-1.565026</td>\n","      <td>0.890675</td>\n","      <td>-1.253276</td>\n","      <td>1.786717</td>\n","      <td>0.320763</td>\n","      <td>2.090712</td>\n","      <td>1.232864</td>\n","      <td>-0.169496</td>\n","      <td>1.034857</td>\n","    </tr>\n","    <tr>\n","      <th>113838</th>\n","      <td>1.884849</td>\n","      <td>-0.143540</td>\n","      <td>-0.999943</td>\n","      <td>1.506772</td>\n","      <td>-0.035300</td>\n","      <td>-0.613638</td>\n","      <td>0.190241</td>\n","      <td>-0.249058</td>\n","      <td>0.666458</td>\n","      <td>0.120908</td>\n","      <td>...</td>\n","      <td>0.144008</td>\n","      <td>0.634646</td>\n","      <td>-0.042114</td>\n","      <td>-0.053206</td>\n","      <td>0.316403</td>\n","      <td>-0.461441</td>\n","      <td>0.018265</td>\n","      <td>-0.041068</td>\n","      <td>0.530986</td>\n","      <td>1.034881</td>\n","    </tr>\n","    <tr>\n","      <th>113839</th>\n","      <td>-0.241923</td>\n","      <td>0.712247</td>\n","      <td>0.399806</td>\n","      <td>-0.463406</td>\n","      <td>0.244531</td>\n","      <td>-1.343668</td>\n","      <td>0.929369</td>\n","      <td>-0.206210</td>\n","      <td>0.106234</td>\n","      <td>-0.284708</td>\n","      <td>...</td>\n","      <td>-0.228876</td>\n","      <td>-0.514376</td>\n","      <td>0.279598</td>\n","      <td>0.371441</td>\n","      <td>-0.559238</td>\n","      <td>0.113144</td>\n","      <td>0.131507</td>\n","      <td>0.081265</td>\n","      <td>-0.230699</td>\n","      <td>1.034904</td>\n","    </tr>\n","    <tr>\n","      <th>113840</th>\n","      <td>0.120316</td>\n","      <td>0.931005</td>\n","      <td>-0.546012</td>\n","      <td>-0.745097</td>\n","      <td>1.130314</td>\n","      <td>-0.235973</td>\n","      <td>0.812722</td>\n","      <td>0.115093</td>\n","      <td>-0.204064</td>\n","      <td>-0.657422</td>\n","      <td>...</td>\n","      <td>-0.314205</td>\n","      <td>-0.808520</td>\n","      <td>0.050343</td>\n","      <td>0.102800</td>\n","      <td>-0.435870</td>\n","      <td>0.124079</td>\n","      <td>0.217940</td>\n","      <td>0.068803</td>\n","      <td>-0.269825</td>\n","      <td>1.034939</td>\n","    </tr>\n","    <tr>\n","      <th>113841</th>\n","      <td>-11.881118</td>\n","      <td>10.071785</td>\n","      <td>-9.834783</td>\n","      <td>-2.066656</td>\n","      <td>-5.364473</td>\n","      <td>-2.606837</td>\n","      <td>-4.918215</td>\n","      <td>7.305334</td>\n","      <td>1.914428</td>\n","      <td>4.356170</td>\n","      <td>...</td>\n","      <td>0.213454</td>\n","      <td>0.111864</td>\n","      <td>1.014480</td>\n","      <td>-0.509348</td>\n","      <td>1.436807</td>\n","      <td>0.250034</td>\n","      <td>0.943651</td>\n","      <td>0.823731</td>\n","      <td>-0.296653</td>\n","      <td>1.034951</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>113842 rows × 30 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcf5e24a-0344-476d-8d15-d65acc6cb6ab')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dcf5e24a-0344-476d-8d15-d65acc6cb6ab button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dcf5e24a-0344-476d-8d15-d65acc6cb6ab');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[""],"metadata":{"id":"_3cpOtPClEnZ"},"execution_count":null,"outputs":[]}]}