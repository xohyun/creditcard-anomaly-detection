{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4858,"status":"ok","timestamp":1658837791381,"user":{"displayName":"김의래","userId":"14322627738803710320"},"user_tz":-540},"id":"u6u81xZmCcSN","outputId":"543117b4-5a46-4ddc-c8b7-0ddb8e429357"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'PyTorch-DAGMM'...\n","remote: Enumerating objects: 102, done.\u001b[K\n","remote: Counting objects: 100% (102/102), done.\u001b[K\n","remote: Compressing objects: 100% (77/77), done.\u001b[K\n","remote: Total 102 (delta 47), reused 61 (delta 20), pack-reused 0\u001b[K\n","Receiving objects: 100% (102/102), 1.83 MiB | 20.79 MiB/s, done.\n","Resolving deltas: 100% (47/47), done.\n","/content/PyTorch-DAGMM\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting barbar\n","  Downloading barbar-0.2.1-py3-none-any.whl (3.9 kB)\n","Installing collected packages: barbar\n","Successfully installed barbar-0.2.1\n"]}],"source":["!git clone https://github.com/mperezcarrasco/PyTorch-DAGMM.git\n","%cd PyTorch-DAGMM\n","!pip install barbar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Olb1Xp4kEgHJ"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd \n","\n","from train import TrainerDAGMM\n","from test import eval\n","from preprocess import get_KDDCup99"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"elapsed":12076,"status":"error","timestamp":1658838272552,"user":{"displayName":"김의래","userId":"14322627738803710320"},"user_tz":-540},"id":"jxIohG9xbg30","outputId":"52f8ba7d-b5cb-4e4e-9e86-15facb0f1076"},"outputs":[{"name":"stdout","output_type":"stream","text":["\r  1024/198371: [>...............................] - ETA 0.0s"]},{"name":"stderr","output_type":"stream","text":["/content/PyTorch-DAGMM/forward_step.py:79: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n","L = torch.cholesky(A)\n","should be replaced with\n","L = torch.linalg.cholesky(A)\n","and\n","U = torch.cholesky(A, upper=True)\n","should be replaced with\n","U = torch.linalg.cholesky(A).mH().\n","This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1744.)\n","  l = torch.cholesky(a, False)\n"]},{"name":"stdout","output_type":"stream","text":["198371/198371: [===============================>] - ETA 0.2s\n","Training DAGMM... Epoch: 0, Loss: 15184518.175\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 1, Loss: 15189973.057\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 2, Loss: 15184839.469\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 3, Loss: 15191626.706\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 4, Loss: 15190298.588\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 5, Loss: 15184957.108\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 6, Loss: 15181274.923\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 7, Loss: 15197577.139\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 8, Loss: 15185708.531\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 9, Loss: 15186443.825\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 10, Loss: 15182531.634\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 11, Loss: 15183462.371\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 12, Loss: 15192399.531\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 13, Loss: 15187795.433\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 14, Loss: 15186280.093\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 15, Loss: 15197116.299\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 16, Loss: 15187971.804\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 17, Loss: 15185797.737\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 18, Loss: 15184007.052\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 19, Loss: 15190043.113\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 20, Loss: 15188565.124\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 21, Loss: 15192053.211\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 22, Loss: 15185870.577\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 23, Loss: 15189753.351\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 24, Loss: 15190934.062\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 25, Loss: 15191973.165\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 26, Loss: 15183087.196\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 27, Loss: 15186618.407\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 28, Loss: 15190442.407\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 29, Loss: 15192679.773\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 30, Loss: 15185699.974\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 31, Loss: 15188229.284\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 32, Loss: 15186585.732\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 33, Loss: 15177823.763\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 34, Loss: 15192258.902\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 35, Loss: 15191996.634\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 36, Loss: 15190372.629\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 37, Loss: 15191874.665\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 38, Loss: 15185800.180\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 39, Loss: 15189083.969\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 40, Loss: 15191327.031\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 41, Loss: 15184262.825\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 42, Loss: 15181683.500\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 43, Loss: 15182741.222\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 44, Loss: 15183642.191\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 45, Loss: 15187170.010\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 46, Loss: 15191339.866\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 47, Loss: 15192840.902\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 48, Loss: 15189760.098\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 49, Loss: 15182634.366\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 50, Loss: 15183416.964\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 51, Loss: 15183882.366\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 52, Loss: 15184862.010\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 53, Loss: 15183620.593\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 54, Loss: 15192543.825\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 55, Loss: 15185358.309\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 56, Loss: 15188006.057\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 57, Loss: 15184647.624\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 58, Loss: 15197240.170\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 59, Loss: 15188867.191\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 60, Loss: 15188412.567\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 61, Loss: 15191313.067\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 62, Loss: 15191314.010\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 63, Loss: 15184646.273\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 64, Loss: 15188043.072\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 65, Loss: 15187312.701\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 66, Loss: 15189047.830\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 67, Loss: 15189902.639\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 68, Loss: 15190426.624\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 69, Loss: 15188180.546\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 70, Loss: 15188854.737\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 71, Loss: 15192474.186\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 72, Loss: 15179956.216\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 73, Loss: 15188985.727\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 74, Loss: 15193794.907\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 75, Loss: 15183319.309\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 76, Loss: 15181944.814\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 77, Loss: 15190313.299\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 78, Loss: 15185461.660\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 79, Loss: 15186547.582\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 80, Loss: 15181607.222\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 81, Loss: 15179263.103\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 82, Loss: 15184964.021\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 83, Loss: 15190983.325\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 84, Loss: 15193879.098\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 85, Loss: 15186906.052\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 86, Loss: 15191808.459\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 87, Loss: 15187215.129\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 88, Loss: 15183597.675\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 89, Loss: 15183986.979\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 90, Loss: 15185020.464\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 91, Loss: 15189866.340\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 92, Loss: 15186191.469\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 93, Loss: 15193362.546\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 94, Loss: 15195382.015\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 95, Loss: 15189859.557\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 96, Loss: 15184782.371\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 97, Loss: 15185679.392\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 98, Loss: 15188885.309\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 99, Loss: 15185190.361\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 100, Loss: 15188876.531\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 101, Loss: 15184903.237\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 102, Loss: 15184721.036\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 103, Loss: 15180735.263\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 104, Loss: 15193386.954\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 105, Loss: 15189111.619\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 106, Loss: 15174122.026\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 107, Loss: 15189379.675\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 108, Loss: 15187585.320\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 109, Loss: 15184626.454\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 110, Loss: 15185844.572\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 111, Loss: 15180384.505\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 112, Loss: 15186536.706\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 113, Loss: 15190339.309\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 114, Loss: 15190272.108\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 115, Loss: 15182395.082\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 116, Loss: 15191996.582\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 117, Loss: 15188077.933\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 118, Loss: 15185039.175\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 119, Loss: 15190453.093\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 120, Loss: 15188713.186\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 121, Loss: 15188001.309\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 122, Loss: 15185917.108\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 123, Loss: 15190105.784\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 124, Loss: 15183263.572\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 125, Loss: 15187978.247\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 126, Loss: 15187172.345\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 127, Loss: 15182207.340\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 128, Loss: 15190675.603\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 129, Loss: 15185180.284\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 130, Loss: 15192349.892\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 131, Loss: 15181410.608\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 132, Loss: 15188377.691\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 133, Loss: 15190097.639\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 134, Loss: 15187456.072\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 135, Loss: 15190591.691\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 136, Loss: 15193544.067\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 137, Loss: 15184142.985\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 138, Loss: 15185977.881\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 139, Loss: 15186097.180\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 140, Loss: 15186300.253\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 141, Loss: 15187723.861\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 142, Loss: 15190817.619\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 143, Loss: 15196978.912\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 144, Loss: 15185535.021\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 145, Loss: 15193708.562\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 146, Loss: 15188352.211\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 147, Loss: 15182287.371\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 148, Loss: 15186867.974\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 149, Loss: 15183675.845\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 150, Loss: 15187640.242\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 151, Loss: 15188963.247\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 152, Loss: 15193967.443\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 153, Loss: 15189727.175\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 154, Loss: 15187435.103\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 155, Loss: 15181701.191\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 156, Loss: 15183670.526\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 157, Loss: 15190075.629\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 158, Loss: 15183603.722\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 159, Loss: 15187111.330\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 160, Loss: 15182017.500\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 161, Loss: 15183438.495\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 162, Loss: 15189486.979\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 163, Loss: 15181743.629\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 164, Loss: 15185448.237\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 165, Loss: 15191032.954\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 166, Loss: 15184097.015\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 167, Loss: 15190757.985\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 168, Loss: 15188948.222\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 169, Loss: 15186261.253\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 170, Loss: 15188045.237\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 171, Loss: 15182407.784\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 172, Loss: 15185455.129\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 173, Loss: 15181748.469\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 174, Loss: 15184025.613\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 175, Loss: 15190904.768\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 176, Loss: 15188898.866\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 177, Loss: 15186467.098\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 178, Loss: 15181270.325\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 179, Loss: 15183541.278\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 180, Loss: 15179091.995\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 181, Loss: 15190963.005\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 182, Loss: 15185623.490\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 183, Loss: 15188452.119\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 184, Loss: 15182110.366\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 185, Loss: 15179621.052\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 186, Loss: 15191542.907\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 187, Loss: 15190628.098\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 188, Loss: 15189322.057\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 189, Loss: 15187346.866\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 190, Loss: 15183621.629\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 191, Loss: 15188462.845\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 192, Loss: 15187939.361\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 193, Loss: 15190249.088\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 194, Loss: 15183249.794\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 195, Loss: 15182070.959\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 196, Loss: 15188271.253\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 197, Loss: 15190589.381\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 198, Loss: 15186632.258\n","198371/198371: [===============================>] - ETA 0.0s\n","Training DAGMM... Epoch: 199, Loss: 15184780.108\n"]}],"source":["class Args:\n","    num_epochs=200\n","    patience=50\n","    lr=1e-4\n","    lr_milestones=[50]\n","    batch_size=1024\n","    latent_dim=1\n","    n_gmm=4\n","    lambda_energy=0.1\n","    lambda_cov=0.005\n","    \n","    \n","args = Args()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","data = get_KDDCup99(args)\n","\n","dagmm = TrainerDAGMM(args, data, device)\n","dagmm.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5480,"status":"ok","timestamp":1658838204810,"user":{"displayName":"김의래","userId":"14322627738803710320"},"user_tz":-540},"id":"M0R8n-ZGbkvX","outputId":"56d63b6b-5207-4785-813e-4c5e2ee1c967"},"outputs":[{"name":"stdout","output_type":"stream","text":["Testing...\n","Precision : 0.8116, Recall : 0.6953, F-score : 0.7489\n","ROC AUC score: 95.07\n"]}],"source":["from test import eval\n","\n","labels, scores = eval(dagmm.model, data, device, args.n_gmm)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":10348,"status":"ok","timestamp":1658838215148,"user":{"displayName":"김의래","userId":"14322627738803710320"},"user_tz":-540},"id":"405KadUocYFp","outputId":"37a88803-de27-459a-9496-45cfa1ec75b5"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["scores_in = scores[np.where(labels==0)[0]]\n","scores_out = scores[np.where(labels==1)[0]]\n","\n","\n","in_ = pd.DataFrame(scores_in, columns=['Inlier'])\n","out_ = pd.DataFrame(scores_out, columns=['Outlier'])\n","\n","\n","fig, ax = plt.subplots()\n","in_.plot.kde(ax=ax, legend=True, title='Outliers vs Inliers (Deep SVDD)')\n","out_.plot.kde(ax=ax, legend=True)\n","ax.grid(axis='x')\n","ax.grid(axis='y')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oS-xk3Oxcc_A"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Untitled0.ipynb","provenance":[],"mount_file_id":"1C3EzuWqhYwAR1jHnagVBdjFoprbnGtF7","authorship_tag":"ABX9TyMmmENGR31knaSSzMxpc0fi"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}