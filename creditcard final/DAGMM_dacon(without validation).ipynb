{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXLs6ZmuwXc7+mxOp2Nyam"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"e43edd0d075c40b6b61121fee080ecaa":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e4555f0b949449af992fc5c10170fd24","IPY_MODEL_78547a0833864f32ae36f0a96e02e6c6"],"layout":"IPY_MODEL_97c37d2897f24189b385ed48e9a8a4cd"}},"e4555f0b949449af992fc5c10170fd24":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11cbb48e7ca84276842b4e5c51a1dd7c","placeholder":"​","style":"IPY_MODEL_bba8f0c7b23b4fffb761827233cef1ba","value":"0.010 MB of 0.010 MB uploaded (0.000 MB deduped)\r"}},"78547a0833864f32ae36f0a96e02e6c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_868777d5fdd24a0d86441b896a0fb0ce","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_097de8aafd0745c6ae87eefd7ca49b9e","value":1}},"97c37d2897f24189b385ed48e9a8a4cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11cbb48e7ca84276842b4e5c51a1dd7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bba8f0c7b23b4fffb761827233cef1ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"868777d5fdd24a0d86441b896a0fb0ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"097de8aafd0745c6ae87eefd7ca49b9e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ik9sLgGJ7G59","executionInfo":{"status":"ok","timestamp":1671004357887,"user_tz":-540,"elapsed":4198,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"a4d1ab6f-4c8b-4ed5-e905-8d38b9372baa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[Errno 2] No such file or directory: 'drive/MyDrive/IITP/sohyun/creditcard_prediction/data'\n","/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/IITP/sohyun/creditcard_prediction/data"]},{"cell_type":"code","source":["!pip install wandb -qqq\n","import wandb\n","wandb.login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P3CNrkhz2jjy","executionInfo":{"status":"ok","timestamp":1671004359979,"user_tz":-540,"elapsed":2098,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"2e153804-5cbe-4ce6-ea05-2a1660053f8d"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["import torch\n","import os\n","import random\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from PIL import Image\n","import h5py\n","import numpy as np\n","import collections\n","import numbers\n","import math\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import numpy as np\n","import os\n","import argparse\n","from torch.backends import cudnn\n","from sklearn.metrics import precision_recall_fscore_support as prf, accuracy_score\n","import time\n","import datetime\n","from torch.autograd import grad\n","from torch.autograd import Variable\n","import matplotlib.pyplot as plt\n","import IPython\n","from tqdm import tqdm\n","\n","torch.manual_seed(0)\n","torch.cuda.manual_seed(0)\n","torch.cuda.manual_seed_all(0)\n","np.random.seed(0)\n","cudnn.benchmark = False\n","cudnn.deterministic = True\n","random.seed(0)"],"metadata":{"id":"61FVN9sCI2gt","executionInfo":{"status":"ok","timestamp":1671004359979,"user_tz":-540,"elapsed":7,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('./train.csv')\n","train_df = train_df.drop(columns=['ID'])\n","val_df = pd.read_csv('./val.csv')\n","val_df = val_df.drop(columns=['ID'])\n","test_df = pd.read_csv('./test.csv')\n","test_df = test_df.drop(columns=['ID'])\n","\n","#-------------------#\n","#---# Normalize #---#\n","#-------------------#\n","# case 1 - standardscaler\n","scaler_n = StandardScaler()\n","scaler_n.fit(train_df)\n","\n","val_x = val_df.drop(columns=['Class'])\n","train_x_scaleN = pd.DataFrame(scaler_n.transform(train_df), columns = train_df.columns) # 확인 : train_x_scaleN.mean(), train_x_scaleN.var()\n","val_x_scaleN = pd.DataFrame(scaler_n.transform(val_x), columns = val_x.columns)\n","test_x_scaleN = pd.DataFrame(scaler_n.transform(test_df), columns = test_df.columns)\n","\n","train_df = train_x_scaleN\n","val_df = pd.concat([val_x_scaleN, pd.DataFrame(val_df['Class'])], axis=1)\n","test_df = test_x_scaleN"],"metadata":{"id":"hsvD9j7WUHEz","executionInfo":{"status":"ok","timestamp":1671004362558,"user_tz":-540,"elapsed":2585,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def to_var(x, volatile=False):\n","    if torch.cuda.is_available():\n","        x = x.cuda()\n","    return Variable(x, volatile=volatile)\n","\n","def mkdir(directory):\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)"],"metadata":{"id":"8ixkP9ze8mE2","executionInfo":{"status":"ok","timestamp":1671004362558,"user_tz":-540,"elapsed":7,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["class KDD99Loader(object):\n","    def __init__(self, data_path, mode=\"train\"):\n","        self.mode=mode\n","\n","        self.train = train_df.values\n","        self.train_labels = np.tile(0, len(train_df))\n","\n","        self.test = val_df.drop(columns = ['Class']).values\n","        self.test_labels = val_df['Class'].values\n","\n","    def __len__(self):\n","        \"\"\"\n","        Number of images in the object dataset.\n","        \"\"\"\n","        if self.mode == \"train\":\n","            return self.train.shape[0]\n","        else:\n","            return self.test.shape[0]\n","\n","    def __getitem__(self, index):\n","        if self.mode == \"train\":\n","            return np.float32(self.train[index]), np.float32(self.train_labels[index])\n","        else:\n","           return np.float32(self.test[index]), np.float32(self.test_labels[index])\n","        \n","\n","def get_loader(data_path, batch_size, mode='train'):\n","    \"\"\"Build and return data loader.\"\"\"\n","\n","    dataset = KDD99Loader(data_path, mode)\n","\n","    shuffle = False\n","    if mode == 'train':\n","        shuffle = True\n","\n","    data_loader = DataLoader(dataset=dataset,\n","                             batch_size=batch_size,\n","                             shuffle=shuffle)\n","    return data_loader"],"metadata":{"id":"uSLkzBK08gZE","executionInfo":{"status":"ok","timestamp":1671004362558,"user_tz":-540,"elapsed":6,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["class Cholesky(torch.autograd.Function):\n","    def forward(ctx, a):\n","        l = torch.cholesky(a, False)\n","        ctx.save_for_backward(l)\n","        return l\n","    def backward(ctx, grad_output):\n","        l, = ctx.saved_variables\n","        linv = l.inverse()\n","        inner = torch.tril(torch.mm(l.t(), grad_output)) * torch.tril(\n","            1.0 - Variable(l.data.new(l.size(1)).fill_(0.5).diag()))\n","        s = torch.mm(linv.t(), torch.mm(inner, linv))\n","        return s\n","    \n","class DaGMM(nn.Module):\n","    \"\"\"Residual Block.\"\"\"\n","    def __init__(self, n_gmm = 4, latent_dim=12):\n","        super(DaGMM, self).__init__()\n","\n","        layers = []\n","        # layers += [nn.Linear(118,60)]\n","        # layers += [nn.Tanh()]        \n","        # layers += [nn.Linear(60,30)]\n","        # layers += [nn.Tanh()]        \n","        layers += [nn.Linear(30,25)]\n","        layers += [nn.Tanh()]         \n","        layers += [nn.Linear(25,20)]\n","        layers += [nn.Tanh()]         \n","        layers += [nn.Linear(20,10)]\n","        # layers += [nn.Tanh()]         \n","        # layers += [nn.Linear(15,10)]\n","\n","        self.encoder = nn.Sequential(*layers)\n","\n","        layers = []\n","        # layers += [nn.Linear(10,15)]\n","        # layers += [nn.Tanh()]        \n","        layers += [nn.Linear(10,20)]\n","        layers += [nn.Tanh()]        \n","        layers += [nn.Linear(20,25)]\n","        layers += [nn.Tanh()]        \n","        layers += [nn.Linear(25,30)]\n","        # layers += [nn.Tanh()]        \n","        # layers += [nn.Linear(60,118)]\n","\n","        self.decoder = nn.Sequential(*layers)\n","\n","        layers = []\n","        layers += [nn.Linear(latent_dim,10)]\n","        layers += [nn.Tanh()]        \n","        layers += [nn.Dropout(p=0.5)]        \n","        layers += [nn.Linear(10,n_gmm)]\n","        layers += [nn.Softmax(dim=1)]\n","\n","\n","        self.estimation = nn.Sequential(*layers)\n","\n","        self.register_buffer(\"phi\", torch.zeros(n_gmm))\n","        self.register_buffer(\"mu\", torch.zeros(n_gmm,latent_dim))\n","        self.register_buffer(\"cov\", torch.zeros(n_gmm,latent_dim,latent_dim))\n","\n","    def relative_euclidean_distance(self, a, b):\n","        return (a-b).norm(2, dim=1) / a.norm(2, dim=1)\n","\n","    def forward(self, x):\n","\n","        enc = self.encoder(x)\n","\n","        dec = self.decoder(enc)\n","\n","        rec_cosine = F.cosine_similarity(x, dec, dim=1)\n","        rec_euclidean = self.relative_euclidean_distance(x, dec)\n","\n","        z = torch.cat([enc, rec_euclidean.unsqueeze(-1), rec_cosine.unsqueeze(-1)], dim=1)\n","\n","        gamma = self.estimation(z)\n","\n","        return enc, dec, z, gamma\n","\n","    def compute_gmm_params(self, z, gamma):\n","        N = gamma.size(0)\n","        # K\n","        sum_gamma = torch.sum(gamma, dim=0)\n","\n","        # K\n","        phi = (sum_gamma / N)\n","\n","        self.phi = phi.data\n","\n"," \n","        # K x D\n","        mu = torch.sum(gamma.unsqueeze(-1) * z.unsqueeze(1), dim=0) / sum_gamma.unsqueeze(-1)\n","        self.mu = mu.data\n","        # z = N x D\n","        # mu = K x D\n","        # gamma N x K\n","\n","        # z_mu = N x K x D\n","        z_mu = (z.unsqueeze(1)- mu.unsqueeze(0))\n","\n","        # z_mu_outer = N x K x D x D\n","        z_mu_outer = z_mu.unsqueeze(-1) * z_mu.unsqueeze(-2)\n","\n","        # K x D x D\n","        cov = torch.sum(gamma.unsqueeze(-1).unsqueeze(-1) * z_mu_outer, dim = 0) / sum_gamma.unsqueeze(-1).unsqueeze(-1)\n","        self.cov = cov.data\n","\n","        return phi, mu, cov\n","        \n","    def compute_energy(self, z, phi=None, mu=None, cov=None, size_average=True):\n","        if phi is None:\n","            phi = to_var(self.phi)\n","        if mu is None:\n","            mu = to_var(self.mu)\n","        if cov is None:\n","            cov = to_var(self.cov)\n","\n","        k, D, _ = cov.size()\n","\n","        z_mu = (z.unsqueeze(1)- mu.unsqueeze(0))\n","\n","        cov_inverse = []\n","        det_cov = []\n","        cov_diag = 0\n","        eps = 1e-12\n","        for i in range(k):\n","            # K x D x D\n","            cov_k = cov[i] + to_var(torch.eye(D)*eps)\n","            cov_inverse.append(torch.inverse(cov_k).unsqueeze(0))\n","\n","            #det_cov.append(np.linalg.det(cov_k.data.cpu().numpy()* (2*np.pi)))\n","            det_cov.append((Cholesky.apply(cov_k.cpu() * (2*np.pi)).diag().prod()).unsqueeze(0))\n","            cov_diag = cov_diag + torch.sum(1 / cov_k.diag())\n","\n","        # K x D x D\n","        cov_inverse = torch.cat(cov_inverse, dim=0)\n","        # K\n","        det_cov = torch.cat(det_cov).cuda()\n","        #det_cov = to_var(torch.from_numpy(np.float32(np.array(det_cov))))\n","\n","        # N x K\n","        exp_term_tmp = -0.5 * torch.sum(torch.sum(z_mu.unsqueeze(-1) * cov_inverse.unsqueeze(0), dim=-2) * z_mu, dim=-1)\n","        # for stability (logsumexp)\n","        max_val = torch.max((exp_term_tmp).clamp(min=0), dim=1, keepdim=True)[0]\n","\n","        exp_term = torch.exp(exp_term_tmp - max_val)\n","\n","        # sample_energy = -max_val.squeeze() - torch.log(torch.sum(phi.unsqueeze(0) * exp_term / (det_cov).unsqueeze(0), dim = 1) + eps)\n","        sample_energy = -max_val.squeeze() - torch.log(torch.sum(phi.unsqueeze(0) * exp_term / (torch.sqrt(det_cov)).unsqueeze(0), dim = 1) + eps)\n","        # sample_energy = -max_val.squeeze() - torch.log(torch.sum(phi.unsqueeze(0) * exp_term / (torch.sqrt((2*np.pi)**D * det_cov)).unsqueeze(0), dim = 1) + eps)\n","\n","\n","        if size_average:\n","            sample_energy = torch.mean(sample_energy)\n","\n","        return sample_energy, cov_diag\n","\n","\n","    def loss_function(self, x, x_hat, z, gamma, lambda_energy, lambda_cov_diag):\n","\n","        recon_error = torch.mean((x - x_hat) ** 2)\n","\n","        phi, mu, cov = self.compute_gmm_params(z, gamma)\n","\n","        sample_energy, cov_diag = self.compute_energy(z, phi, mu, cov)\n","\n","        loss = recon_error + lambda_energy * sample_energy + lambda_cov_diag * cov_diag\n","\n","        return loss, sample_energy, recon_error, cov_diag"],"metadata":{"id":"MplRhuqf8CBe","executionInfo":{"status":"ok","timestamp":1671004362559,"user_tz":-540,"elapsed":6,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class Solver(object):\n","    DEFAULTS = {}   \n","    def __init__(self, data_loader, config):\n","        # Data loader\n","        self.__dict__.update(Solver.DEFAULTS, **config)\n","        self.data_loader = data_loader\n","\n","        # Build tensorboard if use\n","        self.build_model()\n","        # if self.use_tensorboard:\n","        #     self.build_tensorboard()\n","\n","        # Start with trained model\n","        if self.pretrained_model:\n","            self.load_pretrained_model()\n","\n","    def build_model(self):\n","        # Define model\n","        self.dagmm = DaGMM(self.gmm_k)\n","\n","        # Optimizers\n","        self.optimizer = torch.optim.Adam(self.dagmm.parameters(), lr=self.lr)\n","\n","        # Print networks\n","        self.print_network(self.dagmm, 'DaGMM')\n","\n","        if torch.cuda.is_available():\n","            self.dagmm.cuda()\n","\n","    def print_network(self, model, name):\n","        num_params = 0\n","        for p in model.parameters():\n","            num_params += p.numel()\n","        print(name)\n","        print(model)\n","        print(\"The number of parameters: {}\".format(num_params))\n","\n","    def load_pretrained_model(self):\n","        self.dagmm.load_state_dict(torch.load(os.path.join(\n","            self.model_save_path, '{}_dagmm.pth'.format(self.pretrained_model))))\n","\n","        # print(\"phi\", self.dagmm.phi,\"mu\",self.dagmm.mu, \"cov\",self.dagmm.cov)\n","\n","        print('loaded trained models (step: {})..!'.format(self.pretrained_model))\n","\n","    # def build_tensorboard(self):\n","    #     from logger import Logger\n","    #     self.logger = Logger(self.log_path)\n","\n","    def reset_grad(self):\n","        self.dagmm.zero_grad()\n","\n","    def to_var(self, x, volatile=False):\n","        if torch.cuda.is_available():\n","            x = x.cuda()\n","        return Variable(x, volatile=volatile)\n","\n","    def train(self):\n","        iters_per_epoch = len(self.data_loader)\n","\n","        # Start with trained model if exists\n","        if self.pretrained_model:\n","            start = int(self.pretrained_model.split('_')[0])\n","        else:\n","            start = 0\n","\n","        # Start training\n","        iter_ctr = 0\n","        start_time = time.time()\n","      \n","        self.ap_global_train = np.array([0,0,0])\n","        for e in range(start, self.num_epochs):\n","            sum_total_loss = 0; sum_sample_energy = 0; sum_recon_error = 0; sum_cov_diag = 0 \n","            for i, (input_data, labels) in enumerate(tqdm(self.data_loader)):\n","                iter_ctr += 1\n","                start = time.time()\n","\n","                input_data = self.to_var(input_data)\n","\n","                total_loss,sample_energy, recon_error, cov_diag = self.dagmm_step(input_data)\n","                # Logging\n","                loss = {}\n","                loss['total_loss'] = total_loss.data.item()\n","                loss['sample_energy'] = sample_energy.item()\n","                loss['recon_error'] = recon_error.item()\n","                loss['cov_diag'] = cov_diag.item()\n","\n","                sum_total_loss += total_loss.data.item()\n","                sum_sample_energy += sample_energy.item()\n","                sum_recon_error += recon_error.item()\n","                sum_cov_diag += cov_diag.item()\n","\n","\n","                # Print out log info\n","                # if (i+1) % self.log_step == 0:\n","                #     elapsed = time.time() - start_time\n","                #     total_time = ((self.num_epochs*iters_per_epoch)-(e*iters_per_epoch+i)) * elapsed/(e*iters_per_epoch+i+1)\n","                #     epoch_time = (iters_per_epoch-i)* elapsed/(e*iters_per_epoch+i+1)\n","                    \n","                #     epoch_time = str(datetime.timedelta(seconds=epoch_time))\n","                #     total_time = str(datetime.timedelta(seconds=total_time))\n","                #     elapsed = str(datetime.timedelta(seconds=elapsed))\n","\n","                #     lr_tmp = []\n","                #     for param_group in self.optimizer.param_groups:\n","                #         lr_tmp.append(param_group['lr'])\n","                #     tmplr = np.squeeze(np.array(lr_tmp))\n","\n","                #     log = \"Elapsed {}/{} -- {} , Epoch [{}/{}], Iter [{}/{}], lr {}\".format(\n","                #         elapsed,epoch_time,total_time, e+1, self.num_epochs, i+1, iters_per_epoch, tmplr)\n","\n","                #     for tag, value in loss.items():\n","                #         log += \", {}: {:.4f}\".format(tag, value)\n","\n","                #     IPython.display.clear_output()\n","                #     print(log)\n","\n","                    # if self.use_tensorboard:\n","                    #     for tag, value in loss.items():\n","                    #         self.logger.scalar_summary(tag, value, e * iters_per_epoch + i + 1)\n","                    # else:\n","                    #     plt_ctr = 1\n","                    #     if not hasattr(self,\"loss_logs\"):\n","                    #         self.loss_logs = {}\n","                    #         for loss_key in loss:\n","                    #             self.loss_logs[loss_key] = [loss[loss_key]]\n","                    #             plt.subplot(2,2,plt_ctr)\n","                    #             plt.plot(np.array(self.loss_logs[loss_key]), label=loss_key)\n","                    #             plt.legend()\n","                    #             plt_ctr += 1\n","                    #     else:\n","                    #         for loss_key in loss:\n","                    #             self.loss_logs[loss_key].append(loss[loss_key])\n","                    #             plt.subplot(2,2,plt_ctr)\n","                    #             plt.plot(np.array(self.loss_logs[loss_key]), label=loss_key)\n","                    #             plt.legend()\n","                    #             plt_ctr += 1\n","\n","                    #     plt.show()\n","\n","                # print(\"phi\", self.dagmm.phi,\"mu\",self.dagmm.mu, \"cov\",self.dagmm.cov)\n","                # Save model checkpoints\n","            \n","                if (i+1) % self.model_save_step == 0:\n","                    torch.save(self.dagmm.state_dict(),\n","                        os.path.join(self.model_save_path, '{}_{}_dagmm.pth'.format(e+1, i+1)))\n","                    \n","            print(\"total_e\", sum_total_loss)\n","            print(\"\", sum_sample_energy)\n","            print(\"re\", sum_recon_error)\n","            print(\"cov\", sum_cov_diag)\n","            print(\"--\")\n","            wandb.log({\n","                \"total loss\": sum_total_loss,\n","                \"sample energy\": sum_sample_energy,\n","                \"recon error\": sum_recon_error,\n","                \"cov\": sum_cov_diag\n","            })\n","\n","    def dagmm_step(self, input_data):\n","        self.dagmm.train()\n","        enc, dec, z, gamma = self.dagmm(input_data)\n","\n","        total_loss, sample_energy, recon_error, cov_diag = self.dagmm.loss_function(input_data, dec, z, gamma, self.lambda_energy, self.lambda_cov_diag)\n","\n","        self.reset_grad()\n","        total_loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(self.dagmm.parameters(), 5)\n","        self.optimizer.step()\n","\n","        return total_loss,sample_energy, recon_error, cov_diag\n","\n","    def test(self):\n","        print(\"======================TEST MODE======================\")\n","        self.dagmm.eval()\n","        self.data_loader.dataset.mode=\"train\"\n","\n","        N = 0\n","        mu_sum = 0\n","        cov_sum = 0\n","        gamma_sum = 0\n","\n","        for it, (input_data, labels) in enumerate(self.data_loader):\n","            input_data = self.to_var(input_data)\n","            enc, dec, z, gamma = self.dagmm(input_data)\n","            phi, mu, cov = self.dagmm.compute_gmm_params(z, gamma)\n","            \n","            batch_gamma_sum = torch.sum(gamma, dim=0)\n","            \n","            gamma_sum += batch_gamma_sum\n","            mu_sum += mu * batch_gamma_sum.unsqueeze(-1) # keep sums of the numerator only\n","            cov_sum += cov * batch_gamma_sum.unsqueeze(-1).unsqueeze(-1) # keep sums of the numerator only\n","            \n","            N += input_data.size(0)\n","            \n","        train_phi = gamma_sum / N\n","        train_mu = mu_sum / gamma_sum.unsqueeze(-1)\n","        train_cov = cov_sum / gamma_sum.unsqueeze(-1).unsqueeze(-1)\n","\n","        # print(\"N:\",N)\n","        # print(\"phi :\\n\",train_phi)\n","        # print(\"mu :\\n\",train_mu)\n","        # print(\"cov :\\n\",train_cov)\n","\n","        train_energy = []\n","        train_labels = []\n","        train_z = []\n","        for it, (input_data, labels) in enumerate(self.data_loader):\n","            input_data = self.to_var(input_data)\n","            enc, dec, z, gamma = self.dagmm(input_data)\n","            sample_energy, cov_diag = self.dagmm.compute_energy(z, phi=train_phi, mu=train_mu, cov=train_cov, size_average=False)\n","            \n","            train_energy.append(sample_energy.data.cpu().numpy())\n","            train_z.append(z.data.cpu().numpy())\n","            train_labels.append(labels.numpy())\n","\n","\n","        train_energy = np.concatenate(train_energy,axis=0)\n","        train_z = np.concatenate(train_z,axis=0)\n","        train_labels = np.concatenate(train_labels,axis=0)\n","\n","\n","        self.data_loader.dataset.mode=\"test\"\n","        test_energy = []\n","        test_labels = []\n","        test_z = []\n","        for it, (input_data, labels) in enumerate(self.data_loader):\n","            input_data = self.to_var(input_data)\n","            enc, dec, z, gamma = self.dagmm(input_data)\n","            sample_energy, cov_diag = self.dagmm.compute_energy(z, phi=train_phi, mu=train_mu, cov=train_cov, size_average=False)\n","            test_energy.append(sample_energy.data.cpu().numpy())\n","            test_z.append(z.data.cpu().numpy())\n","            test_labels.append(labels.numpy())\n","\n","        test_energy = np.concatenate(test_energy,axis=0)\n","        test_z = np.concatenate(test_z,axis=0)\n","        test_labels = np.concatenate(test_labels,axis=0)\n","\n","        combined_energy = np.concatenate([train_energy, test_energy], axis=0)\n","        combined_labels = np.concatenate([train_labels, test_labels], axis=0)\n","\n","        thresh = np.percentile(combined_energy, 100 - 0.1)\n","        print(\"Threshold :\", thresh)\n","\n","        pred = (test_energy > thresh).astype(int)\n","        gt = test_labels.astype(int)\n","        print(\"================================sum\", sum(gt))\n","        from sklearn.metrics import precision_recall_fscore_support as prf, accuracy_score\n","\n","        accuracy = accuracy_score(gt,pred)\n","        precision, recall, f_score, support = prf(gt, pred, average='macro')\n","        \n","        print(\"Accuracy : {:0.4f}, Precision : {:0.4f}, Recall : {:0.4f}, F-score : {:0.4f}\".format(accuracy, precision, recall, f_score))\n","        \n","        return accuracy, precision, recall, f_score"],"metadata":{"id":"0hkmHEtj8Pce","executionInfo":{"status":"ok","timestamp":1671004363194,"user_tz":-540,"elapsed":10,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["import os\n","import argparse\n","from torch.backends import cudnn\n","\n","def str2bool(v):\n","    return v.lower() in ('true')\n","\n","def main(config):\n","    # For fast training\n","    cudnn.benchmark = True\n","\n","    # Create directories if not exist\n","    mkdir(config.log_path)\n","    mkdir(config.model_save_path)\n","\n","    data_loader = get_loader(config.data_path, batch_size=config.batch_size, mode=config.mode)\n","    \n","    # Solver\n","    solver = Solver(data_loader, vars(config))\n","\n","    if config.mode == 'train':\n","        solver.train()\n","    elif config.mode == 'test':\n","        solver.test()\n","\n","    return solver\n","    \n","if __name__ == '__main__':\n","    wandb.init()\n","    import easydict\n","    args = easydict.EasyDict({\n","        \"num_epochs\" : 40,\n","        \"batch_size\" : 4096,\n","        \"gmm_k\" : 100, #3\n","        \"lambda_energy\" : 0.1,\n","        \"lambda_cov_diag\" : 0.005,\n","        # \"pretrained_model\" : '',\n","        \"pretrained_model\" : None,\n","        \"mode\" : 'train',\n","        # \"mode\" : \"test\",\n","        # \"data_path\" : \"./kdd_cup.npz\",\n","        \"data_path\" : None, \n","        \"use_tensorboard\" : False,\n","        \"log_path\" : './logs',\n","        \"model_save_path\" : './models',\n","        \"log_step\" : 194//4,\n","        \"sample_step\" : 194,\n","        \"model_save_step\" : 194,\n","        \"lr\" : 1e-7, #2e-5\n","        \"wd\" : None\n","    })\n","    config = args\n"," \n","    print('------------ Options -------------')\n","    for k, v in sorted(args.items()):\n","        print('%s: %s' % (str(k), str(v)))\n","    print('-------------- End ----------------')\n","\n","    solver = main(config)\n","    solver.test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e43edd0d075c40b6b61121fee080ecaa","e4555f0b949449af992fc5c10170fd24","78547a0833864f32ae36f0a96e02e6c6","97c37d2897f24189b385ed48e9a8a4cd","11cbb48e7ca84276842b4e5c51a1dd7c","bba8f0c7b23b4fffb761827233cef1ba","868777d5fdd24a0d86441b896a0fb0ce","097de8aafd0745c6ae87eefd7ca49b9e"]},"id":"O0vLb9Gp7pjL","executionInfo":{"status":"ok","timestamp":1671004581272,"user_tz":-540,"elapsed":218086,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"9f0bb353-4584-4bf7-86b8-bbc69576864f"},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:2a7itpya) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e43edd0d075c40b6b61121fee080ecaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">rare-wildflower-416</strong>: <a href=\"https://wandb.ai/sohyun/uncategorized/runs/2a7itpya\" target=\"_blank\">https://wandb.ai/sohyun/uncategorized/runs/2a7itpya</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221214_075219-2a7itpya/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:2a7itpya). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data/wandb/run-20221214_075242-1yq9vlu5</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/sohyun/uncategorized/runs/1yq9vlu5\" target=\"_blank\">expert-water-417</a></strong> to <a href=\"https://wandb.ai/sohyun/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------------ Options -------------\n","batch_size: 4096\n","data_path: None\n","gmm_k: 100\n","lambda_cov_diag: 0.005\n","lambda_energy: 0.1\n","log_path: ./logs\n","log_step: 48\n","lr: 1e-07\n","mode: train\n","model_save_path: ./models\n","model_save_step: 194\n","num_epochs: 40\n","pretrained_model: None\n","sample_step: 194\n","use_tensorboard: False\n","wd: None\n","-------------- End ----------------\n","DaGMM\n","DaGMM(\n","  (encoder): Sequential(\n","    (0): Linear(in_features=30, out_features=25, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=25, out_features=20, bias=True)\n","    (3): Tanh()\n","    (4): Linear(in_features=20, out_features=10, bias=True)\n","  )\n","  (decoder): Sequential(\n","    (0): Linear(in_features=10, out_features=20, bias=True)\n","    (1): Tanh()\n","    (2): Linear(in_features=20, out_features=25, bias=True)\n","    (3): Tanh()\n","    (4): Linear(in_features=25, out_features=30, bias=True)\n","  )\n","  (estimation): Sequential(\n","    (0): Linear(in_features=12, out_features=10, bias=True)\n","    (1): Tanh()\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=10, out_features=100, bias=True)\n","    (4): Softmax(dim=1)\n","  )\n",")\n","The number of parameters: 4260\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/28 [00:00<?, ?it/s]<ipython-input-27-16826e21c896>:3: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n","L = torch.cholesky(A)\n","should be replaced with\n","L = torch.linalg.cholesky(A)\n","and\n","U = torch.cholesky(A, upper=True)\n","should be replaced with\n","U = torch.linalg.cholesky(A).mH().\n","This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1615.)\n","  l = torch.cholesky(a, False)\n","<ipython-input-27-16826e21c896>:7: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n","  l, = ctx.saved_variables\n","100%|██████████| 28/28 [00:12<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18871.164428710938\n"," -109.31263065338135\n","re 28.706895887851715\n","cov 3770677.796875\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18872.585327148438\n"," -109.30487179756165\n","re 28.69761770963669\n","cov 3770963.71875\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18865.86016845703\n"," -109.28481841087341\n","re 28.71396505832672\n","cov 3769615.015625\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18859.863891601562\n"," -109.27369928359985\n","re 28.71253204345703\n","cov 3768415.828125\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18858.153747558594\n"," -109.28158235549927\n","re 28.727710485458374\n","cov 3768070.9375\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18851.619873046875\n"," -109.26670622825623\n","re 28.712534189224243\n","cov 3766766.953125\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18847.879638671875\n"," -109.23039293289185\n","re 28.719804883003235\n","cov 3766016.671875\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18848.834838867188\n"," -109.24386954307556\n","re 28.70403426885605\n","cov 3766211.1328125\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18839.581298828125\n"," -109.22200107574463\n","re 28.712266206741333\n","cov 3764358.328125\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18834.50634765625\n"," -109.18837308883667\n","re 28.71425759792328\n","cov 3763342.25\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18826.778869628906\n"," -109.19400119781494\n","re 28.719788253307343\n","cov 3761795.7421875\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18826.954956054688\n"," -109.1831283569336\n","re 28.71520882844925\n","cov 3761831.671875\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18821.890014648438\n"," -109.19259285926819\n","re 28.697118282318115\n","cov 3760822.546875\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18815.53887939453\n"," -109.14652252197266\n","re 28.700605928897858\n","cov 3759550.640625\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18817.930419921875\n"," -109.18253755569458\n","re 28.68492430448532\n","cov 3760032.84375\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18811.053771972656\n"," -109.13675141334534\n","re 28.725898385047913\n","cov 3758648.3828125\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18806.62384033203\n"," -109.14232349395752\n","re 28.714838564395905\n","cov 3757764.6953125\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18799.634887695312\n"," -109.11279201507568\n","re 28.711279094219208\n","cov 3756367.0625\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:05<00:00,  5.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18793.771423339844\n"," -109.09647607803345\n","re 28.712045967578888\n","cov 3755193.890625\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:05<00:00,  5.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18794.980224609375\n"," -109.08214902877808\n","re 28.73019027709961\n","cov 3755431.7265625\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18788.023803710938\n"," -109.07459592819214\n","re 28.72842812538147\n","cov 3754040.6484375\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18780.526245117188\n"," -109.05065727233887\n","re 28.716763377189636\n","cov 3752543.0\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18779.94305419922\n"," -109.05795526504517\n","re 28.698639690876007\n","cov 3752430.1640625\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18770.49102783203\n"," -109.03194332122803\n","re 28.712785065174103\n","cov 3750536.359375\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18766.125549316406\n"," -109.01982378959656\n","re 28.703332364559174\n","cov 3749664.921875\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:05<00:00,  5.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18764.977661132812\n"," -109.02040696144104\n","re 28.724046885967255\n","cov 3749431.2265625\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18759.309997558594\n"," -108.99886965751648\n","re 28.72506493330002\n","cov 3748297.0625\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18753.164489746094\n"," -108.99628043174744\n","re 28.712769031524658\n","cov 3747070.34375\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18749.774963378906\n"," -108.97825837135315\n","re 28.716729819774628\n","cov 3746391.2734375\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18750.7626953125\n"," -108.95702075958252\n","re 28.71041965484619\n","cov 3746589.6796875\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18743.665100097656\n"," -108.96827721595764\n","re 28.722317814826965\n","cov 3745168.0\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:05<00:00,  4.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18739.580078125\n"," -108.9532482624054\n","re 28.74734479188919\n","cov 3744345.703125\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18731.052307128906\n"," -108.91137790679932\n","re 28.722871005535126\n","cov 3742644.1640625\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18729.465576171875\n"," -108.93200325965881\n","re 28.709672033786774\n","cov 3742329.90625\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18724.55792236328\n"," -108.9328818321228\n","re 28.715925097465515\n","cov 3741347.203125\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18719.908325195312\n"," -108.89609169960022\n","re 28.724315285682678\n","cov 3740414.8203125\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18718.756958007812\n"," -108.88517189025879\n","re 28.72086888551712\n","cov 3740185.0078125\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18711.672973632812\n"," -108.88088345527649\n","re 28.70246559381485\n","cov 3738771.7421875\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18707.491943359375\n"," -108.85461258888245\n","re 28.706371545791626\n","cov 3737934.328125\n","--\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:04<00:00,  5.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total_e 18698.524963378906\n"," -108.8389663696289\n","re 28.724519729614258\n","cov 3736136.9296875\n","--\n","======================TEST MODE======================\n","Threshold : 27.631006240844727\n","================================sum 30\n","Accuracy : 0.9991, Precision : 0.7855, Recall : 0.7665, F-score : 0.7756\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ZLmJzVfFniAf","executionInfo":{"status":"ok","timestamp":1671004581273,"user_tz":-540,"elapsed":3,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":29,"outputs":[]}]}