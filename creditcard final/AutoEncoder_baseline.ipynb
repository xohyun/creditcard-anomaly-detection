{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1GtDfKW90iDn_irx9Ij7ckkNpI2VtLWvQ","authorship_tag":"ABX9TyMp91x65BBQJ7ieadnVcOYx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","# drive.mount('/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data')\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/IITP/sohyun/creditcard_prediction/data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aoTfHzuB_M7u","executionInfo":{"status":"ok","timestamp":1670998538207,"user_tz":-540,"elapsed":26794,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"0565e8a1-df6d-4df9-e27f-cd352b5ef663"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data\n"]}]},{"cell_type":"code","source":["!pip install wandb -qqq\n","import wandb\n","wandb.login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"id":"pyCrbam-X2js","executionInfo":{"status":"ok","timestamp":1670998563825,"user_tz":-540,"elapsed":22003,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"1fc22681-6f48-4f93-d9c2-5750ca2cd4cc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.9 MB 30.6 MB/s \n","\u001b[K     |████████████████████████████████| 182 kB 69.2 MB/s \n","\u001b[K     |████████████████████████████████| 168 kB 71.6 MB/s \n","\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n","\u001b[K     |████████████████████████████████| 168 kB 78.9 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 78.8 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 86.7 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 68.9 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 53.4 MB/s \n","\u001b[K     |████████████████████████████████| 158 kB 85.8 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 76.8 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 84.4 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 82.7 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 83.2 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 57.7 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 86.7 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 82.5 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 81.8 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"gPauNGcl-kic","executionInfo":{"status":"ok","timestamp":1670998599513,"user_tz":-540,"elapsed":31706,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"outputs":[],"source":["import random\n","import pandas as pd\n","import numpy as np\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","# wandb.init(project=\"\") # wandb init\n","SEED = 1004\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(SEED) # Seed 고정\n","\n","train_df = pd.read_csv('./train.csv')\n","train_df = train_df.drop(columns=['ID'])\n","val_df = pd.read_csv('./val.csv')\n","val_df = val_df.drop(columns=['ID'])\n","test_df = pd.read_csv('./test.csv')\n","test_df = test_df.drop(columns=['ID'])\n","\n","# 분포 고려해서 train_df 정제\n","contamination = 0.0010551\n","thrs = []\n","for i in range(30) :\n","  a = train_df.iloc[:,i].quantile(contamination/2)\n","  b = train_df.iloc[:,i].quantile(1 - contamination/2)\n","  thrs.append([a,b])\n","\n","idxs = []; idx1 = 0; idx2 = 0\n","for i in range(30) :\n","  c_name = \"V\" + str(i+1)\n","  idx1 = train_df[(train_df[[c_name]] <= thrs[i][0])][[c_name]].values.flatten()\n","  idx1 = np.where([np.logical_not(np.isnan(idx1))])[1]\n","  \n","  idx2 = train_df[(train_df[[c_name]] >= thrs[i][1])][[c_name]].values.flatten()\n","  idx2 = np.where([np.logical_not(np.isnan(idx2))])[1]\n","\n","  idxs.extend(np.concatenate((idx1, idx2)))\n","\n","from collections import Counter\n","counter = Counter(idxs)\n","\n","pseudo_anomal = []\n","for k, v in dict(counter).items():\n","  if v >= 8 :\n","    pseudo_anomal.append(k)\n","\n","train_df = train_df.drop(pseudo_anomal).reset_index(drop=True)\n","\n","#-------------------#\n","#---# Normalize #---#\n","#-------------------#\n","# case 1 - standardscaler\n","# from sklearn.preprocessing import StandardScaler\n","# scaler_n = StandardScaler()\n","# scaler_n.fit(train_df)\n","\n","# val_x = val_df.drop(columns=['Class'])\n","# train_x_scaleN = pd.DataFrame(scaler_n.transform(train_df), columns = train_df.columns) # 확인 : train_x_scaleN.mean(), train_x_scaleN.var()\n","# val_x_scaleN = pd.DataFrame(scaler_n.transform(val_x), columns = val_x.columns)\n","# test_x_scaleN = pd.DataFrame(scaler_n.transform(test_df), columns = test_df.columns)\n","\n","# train_df = train_x_scaleN\n","# val_df = pd.concat([val_x_scaleN, pd.DataFrame(val_df['Class'])], axis=1)\n","# test_df = test_x_scaleN"]},{"cell_type":"code","source":["EPOCHS = 400\n","LR = 1e-2\n","BS = 16384\n","WD = None #1e-4\n","\n","class MyDataset(Dataset):\n","    def __init__(self, df, eval_mode):\n","        self.df = df\n","        self.eval_mode = eval_mode\n","        if self.eval_mode:\n","            self.labels = self.df['Class'].values\n","            self.df = self.df.drop(columns=['Class']).values\n","        else:\n","            self.df = self.df.values\n","        \n","    def __getitem__(self, index):\n","        if self.eval_mode:\n","            self.x = self.df[index]\n","            self.y = self.labels[index]\n","            return torch.Tensor(self.x), self.y\n","        else:\n","            self.x = self.df[index]\n","            return torch.Tensor(self.x)\n","        \n","    def __len__(self):\n","        return len(self.df)\n","\n","train_dataset = MyDataset(df=train_df, eval_mode=False)\n","train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n","\n","val_dataset = MyDataset(df = val_df, eval_mode=True)\n","val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False)\n","\n","test_dataset = MyDataset(test_df, False)\n","test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=6)\n","\n","class AutoEncoder(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","        self.Encoder = nn.Sequential(\n","            nn.Linear(30,64),\n","            nn.BatchNorm1d(64),\n","            # nn.LayerNorm(64),\n","            nn.LeakyReLU(),\n","            # nn.ReLU(),\n","            nn.Linear(64,128),\n","            nn.BatchNorm1d(128),\n","            # nn.LayerNorm(128),\n","            nn.LeakyReLU(),\n","            # nn.ReLU()\n","        )\n","        self.Decoder = nn.Sequential(\n","            nn.Linear(128,64),\n","            nn.BatchNorm1d(64),\n","            # nn.LayerNorm(64),\n","            nn.LeakyReLU(),\n","            # nn.ReLU(),\n","            nn.Linear(64,30)\n","        )\n","        \n","    def forward(self, x):\n","        x = self.Encoder(x)\n","        x = self.Decoder(x)\n","        return x\n","\n","class Trainer():\n","    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.scheduler = scheduler\n","        self.device = device\n","        # Loss Function\n","        self.criterion = nn.L1Loss().to(self.device)\n","        \n","    def fit(self, ):\n","        self.model.to(self.device)\n","        best_score = 0\n","        for epoch in range(EPOCHS):\n","            self.model.train()\n","            train_loss = []\n","            for x in iter(self.train_loader):\n","                x = x.float().to(self.device)\n","                self.optimizer.zero_grad()\n","\n","                _x = self.model(x)\n","                loss = self.criterion(x, _x)\n","\n","                loss.backward()\n","                self.optimizer.step()\n","\n","                train_loss.append(loss.item())\n","\n","            score = self.validation(self.model, 0.95)\n","            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n","\n","            if self.scheduler is not None:\n","                self.scheduler.step(score)\n","\n","            if best_score < score:\n","                best_score = score\n","                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n","            wandb.log({\n","                \"validation f1\": score\n","            })\n","    \n","    def validation(self, eval_model, thr):\n","        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","        eval_model.eval()\n","        pred = []\n","        true = []\n","        with torch.no_grad():\n","            for x, y in iter(self.val_loader):\n","                x = x.float().to(self.device)\n","\n","                _x = self.model(x)\n","                diff = cos(x, _x).cpu().tolist()\n","                batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n","                pred += batch_pred\n","                true += y.tolist()\n","\n","        return f1_score(true, pred, average='macro')\n","\n","wandb.init()\n","model = nn.DataParallel(AutoEncoder())\n","model.eval()\n","if WD : optimizer = torch.optim.Adam(params = model.parameters(), lr = LR, weight_decay=WD)\n","else : optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n","\n","trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n","trainer.fit()"],"metadata":{"id":"kijk5u73jo-B","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1670998806030,"user_tz":-540,"elapsed":143298,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"643981e2-49ef-42b2-d3d6-b7a27518fcf3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msohyun\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data/wandb/run-20221214_061742-2pqw4m48</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/sohyun/uncategorized/runs/2pqw4m48\" target=\"_blank\">icy-rain-412</a></strong> to <a href=\"https://wandb.ai/sohyun/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch : [0] Train loss : [0.5485392894063678] Val Score : [0.0012289392130924502])\n","Epoch : [1] Train loss : [0.3711425619465964] Val Score : [0.06540554760449138])\n","Epoch : [2] Train loss : [0.28061316694532124] Val Score : [0.25081745953177564])\n","Epoch : [3] Train loss : [0.22154577927930014] Val Score : [0.3798491873512216])\n","Epoch : [4] Train loss : [0.18546087401253836] Val Score : [0.4541809465985865])\n","Epoch : [5] Train loss : [0.16224002625261033] Val Score : [0.4759860512628576])\n","Epoch : [6] Train loss : [0.14575864587511336] Val Score : [0.4899898390669877])\n","Epoch : [7] Train loss : [0.13478387679372514] Val Score : [0.49526880187208155])\n","Epoch : [8] Train loss : [0.1262592939393861] Val Score : [0.4974397204297202])\n","Epoch : [9] Train loss : [0.12121715396642685] Val Score : [0.5006412049132671])\n","Epoch : [10] Train loss : [0.11542644990342003] Val Score : [0.5017503007041467])\n","Epoch : [11] Train loss : [0.11129964568785258] Val Score : [0.50294115484341])\n","Epoch : [12] Train loss : [0.1088873999459403] Val Score : [0.5039546987889401])\n","Epoch : [13] Train loss : [0.10485974912132535] Val Score : [0.5048562793580369])\n","Epoch : [14] Train loss : [0.10276069385664803] Val Score : [0.5056124637716857])\n","Epoch : [15] Train loss : [0.09907311946153641] Val Score : [0.5068453365265819])\n","Epoch : [16] Train loss : [0.09805852919816971] Val Score : [0.5089974228133562])\n","Epoch : [17] Train loss : [0.09563019233090538] Val Score : [0.5146393687846859])\n","Epoch : [18] Train loss : [0.09028652416808265] Val Score : [0.5254002744367214])\n","Epoch : [19] Train loss : [0.08718836946146828] Val Score : [0.5275341662507901])\n","Epoch : [20] Train loss : [0.08431169390678406] Val Score : [0.529049612167974])\n","Epoch : [21] Train loss : [0.08422058714287621] Val Score : [0.5312272431088949])\n","Epoch : [22] Train loss : [0.08265071255820138] Val Score : [0.533961629238583])\n","Epoch : [23] Train loss : [0.08060946741274425] Val Score : [0.5349664116227172])\n","Epoch : [24] Train loss : [0.07848268853766578] Val Score : [0.5360877494307982])\n","Epoch : [25] Train loss : [0.07634524468864713] Val Score : [0.5370204714222725])\n","Epoch : [26] Train loss : [0.07280236589057106] Val Score : [0.5371791564892391])\n","Epoch : [27] Train loss : [0.07376346737146378] Val Score : [0.5412036648612704])\n","Epoch : [28] Train loss : [0.07167111869369235] Val Score : [0.5421410861959591])\n","Epoch : [29] Train loss : [0.07197449249880654] Val Score : [0.5438093350896822])\n","Epoch : [30] Train loss : [0.07141790964773723] Val Score : [0.5459036024684233])\n","Epoch : [31] Train loss : [0.07171401168618884] Val Score : [0.5466732098311047])\n","Epoch : [32] Train loss : [0.07069075001137597] Val Score : [0.5508445183715132])\n","Epoch : [33] Train loss : [0.0686998942068645] Val Score : [0.5546325411730989])\n","Epoch : [34] Train loss : [0.06736844990934644] Val Score : [0.554204854984325])\n","Epoch : [35] Train loss : [0.06533032762152809] Val Score : [0.5564006733516096])\n","Epoch : [36] Train loss : [0.06434997330818858] Val Score : [0.5585878582510984])\n","Epoch : [37] Train loss : [0.06529278095279421] Val Score : [0.5625091554978082])\n","Epoch : [38] Train loss : [0.06526655490909304] Val Score : [0.5659055053857034])\n","Epoch : [39] Train loss : [0.06520428721393857] Val Score : [0.5749877626356633])\n","Epoch : [40] Train loss : [0.06440127108778272] Val Score : [0.5828796784473987])\n","Epoch : [41] Train loss : [0.06114563984530313] Val Score : [0.5966253027265187])\n","Epoch : [42] Train loss : [0.05997386681182044] Val Score : [0.6425856499063244])\n","Epoch : [43] Train loss : [0.05836870734180723] Val Score : [0.6803845814211198])\n","Epoch : [44] Train loss : [0.057995740856443136] Val Score : [0.699339777108752])\n","Epoch : [45] Train loss : [0.05679808557033539] Val Score : [0.699339777108752])\n","Epoch : [46] Train loss : [0.0575416912989957] Val Score : [0.699339777108752])\n","Epoch : [47] Train loss : [0.05764890302504812] Val Score : [0.7026094381998027])\n","Epoch : [48] Train loss : [0.05737416126898357] Val Score : [0.6961725409972995])\n","Epoch : [49] Train loss : [0.05788199124591691] Val Score : [0.7059866032567539])\n","Epoch : [50] Train loss : [0.057241392987115045] Val Score : [0.7009614947751022])\n","Epoch : [51] Train loss : [0.05633786746433803] Val Score : [0.7042842522861986])\n","Epoch : [52] Train loss : [0.055581399372645786] Val Score : [0.7094766927103557])\n","Epoch : [53] Train loss : [0.05531720391341618] Val Score : [0.7094766927103557])\n","Epoch : [54] Train loss : [0.05366978581462588] Val Score : [0.7187349645015549])\n","Epoch : [55] Train loss : [0.051700763936553686] Val Score : [0.7112658784551884])\n","Epoch : [56] Train loss : [0.051939550787210464] Val Score : [0.7026094381998027])\n","Epoch : [57] Train loss : [0.05190231331757137] Val Score : [0.7094766927103557])\n","Epoch : [58] Train loss : [0.05317763664892742] Val Score : [0.714936337281296])\n","Epoch : [59] Train loss : [0.05173288232513836] Val Score : [0.7059866032567539])\n","Epoch : [60] Train loss : [0.051659923046827316] Val Score : [0.7059866032567539])\n","Epoch : [61] Train loss : [0.05510342440434864] Val Score : [0.7168192118976862])\n","Epoch : [62] Train loss : [0.053822961768933704] Val Score : [0.7130854976190938])\n","Epoch : [63] Train loss : [0.05335567572287151] Val Score : [0.7246883762645999])\n","Epoch : [64] Train loss : [0.05412601466689791] Val Score : [0.7094766927103557])\n","Epoch : [65] Train loss : [0.052155482449701855] Val Score : [0.7226686263465465])\n","Epoch : [66] Train loss : [0.051919739693403244] Val Score : [0.714936337281296])\n","Epoch : [67] Train loss : [0.05324293885912214] Val Score : [0.7288385690883094])\n","Epoch : [68] Train loss : [0.05370626492159707] Val Score : [0.7246883762645999])\n","Epoch : [69] Train loss : [0.051745438149997165] Val Score : [0.7206844679680786])\n","Epoch : [70] Train loss : [0.049403052777051926] Val Score : [0.7246883762645999])\n","Epoch : [71] Train loss : [0.04746571555733681] Val Score : [0.7353562550268086])\n","Epoch : [72] Train loss : [0.04731403184788568] Val Score : [0.7399094305905288])\n","Epoch : [73] Train loss : [0.04877575061150959] Val Score : [0.7226686263465465])\n","Epoch : [74] Train loss : [0.047688965286527364] Val Score : [0.7226686263465465])\n","Epoch : [75] Train loss : [0.04669834513749395] Val Score : [0.7376112450647377])\n","Epoch : [76] Train loss : [0.047741630779845376] Val Score : [0.7331432493795871])\n","Epoch : [77] Train loss : [0.05016169590609414] Val Score : [0.730971061881369])\n","Epoch : [78] Train loss : [0.04927273201090949] Val Score : [0.7422520697342344])\n","Epoch : [79] Train loss : [0.047500326697315486] Val Score : [0.7376112450647377])\n","Epoch : [80] Train loss : [0.04529202835900443] Val Score : [0.7376112450647377])\n","Epoch : [81] Train loss : [0.04741765558719635] Val Score : [0.7470759905302604])\n","Epoch : [82] Train loss : [0.047522389463015964] Val Score : [0.7422520697342344])\n","Epoch : [83] Train loss : [0.04904408486826079] Val Score : [0.752094104263044])\n","Epoch : [84] Train loss : [0.049298362008162906] Val Score : [0.7600119366040216])\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-a4102e5b2d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-a4102e5b2d45>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_in_batch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0midx_in_batch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0midx_in_batch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                     \u001b[0midx_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["For test"],"metadata":{"id":"Im5EjnwySiJ3"}},{"cell_type":"code","source":["model = AutoEncoder()\n","model.load_state_dict(torch.load('./best_model.pth'))\n","model = nn.DataParallel(model)\n","model.eval()\n","\n","def prediction(model, thr, test_loader, device):\n","    model.to(device)\n","    model.eval()\n","    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","    pred = []\n","    with torch.no_grad():\n","        for x in iter(test_loader):\n","            x = x.float().to(device)\n","            \n","            _x = model(x)\n","            \n","            diff = cos(x, _x).cpu().tolist()\n","            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n","            pred += batch_pred\n","    return pred\n","\n","preds = prediction(model, 0.97, test_loader, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOLXoEwK8TqY","executionInfo":{"status":"ok","timestamp":1657790072472,"user_tz":-540,"elapsed":2848,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"32c4af9c-5b8b-4beb-e760-db42aecb884b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"markdown","source":["For submit"],"metadata":{"id":"ffQ9wAeIScL1"}},{"cell_type":"code","source":["submit = pd.read_csv('./sample_submission.csv')\n","submit['Class'] = preds\n","submit.to_csv('./submit_autoencoder2.csv', index=False)"],"metadata":{"id":"IgdZWXD0IJkR"},"execution_count":null,"outputs":[]}]}