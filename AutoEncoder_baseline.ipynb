{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AutoEncoder_baseline.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1GtDfKW90iDn_irx9Ij7ckkNpI2VtLWvQ","authorship_tag":"ABX9TyMreCyQk6DjMfhh4pJ6QTVw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"0d6b3de3030e4631ac20da79851f3dc0":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_5f96a7dec45f48e18cb52a3f38e8899f","IPY_MODEL_1697aa8fa13a4748a03c534a285d88f0"],"layout":"IPY_MODEL_c23508aa891a4ceb9ba7ce95276e260a"}},"5f96a7dec45f48e18cb52a3f38e8899f":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0406b7a0ebf4945b449b5c3d23f8740","placeholder":"​","style":"IPY_MODEL_da58b0fe54ef47df9fedb0cc91f153d8","value":"0.029 MB of 0.029 MB uploaded (0.000 MB deduped)\r"}},"1697aa8fa13a4748a03c534a285d88f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2d54ad84a714341a6e6deaa6c1664c4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25e00f2897dd48a6b6c895416a0862ec","value":1}},"c23508aa891a4ceb9ba7ce95276e260a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0406b7a0ebf4945b449b5c3d23f8740":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da58b0fe54ef47df9fedb0cc91f153d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2d54ad84a714341a6e6deaa6c1664c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25e00f2897dd48a6b6c895416a0862ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","# drive.mount('/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data')\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/IITP/sohyun/creditcard_prediction/data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aoTfHzuB_M7u","executionInfo":{"status":"ok","timestamp":1659874879551,"user_tz":-540,"elapsed":29714,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"f0523aac-c1be-48c6-a1e8-532a7a16aaaa"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data\n"]}]},{"cell_type":"code","source":["!pip install wandb -qqq\n","import wandb\n","wandb.login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":199},"id":"pyCrbam-X2js","executionInfo":{"status":"ok","timestamp":1659875427839,"user_tz":-540,"elapsed":17114,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"34b1c733-4601-432c-a717-1e030622f495"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.8 MB 14.9 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 58.5 MB/s \n","\u001b[K     |████████████████████████████████| 181 kB 59.2 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 74.9 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 74.9 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"gPauNGcl-kic","executionInfo":{"status":"ok","timestamp":1659875381086,"user_tz":-540,"elapsed":24432,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"outputs":[],"source":["import random\n","import pandas as pd\n","import numpy as np\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","# wandb.init(project=\"\") # wandb init\n","SEED = 1004\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(SEED) # Seed 고정\n","\n","train_df = pd.read_csv('./train.csv')\n","train_df = train_df.drop(columns=['ID'])\n","val_df = pd.read_csv('./val.csv')\n","val_df = val_df.drop(columns=['ID'])\n","test_df = pd.read_csv('./test.csv')\n","test_df = test_df.drop(columns=['ID'])\n","\n","# 분포 고려해서 train_df 정제\n","contamination = 0.0010551\n","thrs = []\n","for i in range(30) :\n","  a = train_df.iloc[:,i].quantile(contamination/2)\n","  b = train_df.iloc[:,i].quantile(1 - contamination/2)\n","  thrs.append([a,b])\n","\n","idxs = []; idx1 = 0; idx2 = 0\n","for i in range(30) :\n","  c_name = \"V\" + str(i+1)\n","  idx1 = train_df[(train_df[[c_name]] <= thrs[i][0])][[c_name]].values.flatten()\n","  idx1 = np.where([np.logical_not(np.isnan(idx1))])[1]\n","  \n","  idx2 = train_df[(train_df[[c_name]] >= thrs[i][1])][[c_name]].values.flatten()\n","  idx2 = np.where([np.logical_not(np.isnan(idx2))])[1]\n","\n","  idxs.extend(np.concatenate((idx1, idx2)))\n","\n","from collections import Counter\n","counter = Counter(idxs)\n","\n","pseudo_anomal = []\n","for k, v in dict(counter).items():\n","  if v >= 8 :\n","    pseudo_anomal.append(k)\n","\n","train_df = train_df.drop(pseudo_anomal).reset_index(drop=True)\n","\n","#-------------------#\n","#---# Normalize #---#\n","#-------------------#\n","# case 1 - standardscaler\n","# from sklearn.preprocessing import StandardScaler\n","# scaler_n = StandardScaler()\n","# scaler_n.fit(train_df)\n","\n","# val_x = val_df.drop(columns=['Class'])\n","# train_x_scaleN = pd.DataFrame(scaler_n.transform(train_df), columns = train_df.columns) # 확인 : train_x_scaleN.mean(), train_x_scaleN.var()\n","# val_x_scaleN = pd.DataFrame(scaler_n.transform(val_x), columns = val_x.columns)\n","# test_x_scaleN = pd.DataFrame(scaler_n.transform(test_df), columns = test_df.columns)\n","\n","# train_df = train_x_scaleN\n","# val_df = pd.concat([val_x_scaleN, pd.DataFrame(val_df['Class'])], axis=1)\n","# test_df = test_x_scaleN"]},{"cell_type":"code","source":["EPOCHS = 400\n","LR = 1e-2\n","BS = 16384\n","WD = None #1e-4\n","\n","class MyDataset(Dataset):\n","    def __init__(self, df, eval_mode):\n","        self.df = df\n","        self.eval_mode = eval_mode\n","        if self.eval_mode:\n","            self.labels = self.df['Class'].values\n","            self.df = self.df.drop(columns=['Class']).values\n","        else:\n","            self.df = self.df.values\n","        \n","    def __getitem__(self, index):\n","        if self.eval_mode:\n","            self.x = self.df[index]\n","            self.y = self.labels[index]\n","            return torch.Tensor(self.x), self.y\n","        else:\n","            self.x = self.df[index]\n","            return torch.Tensor(self.x)\n","        \n","    def __len__(self):\n","        return len(self.df)\n","\n","train_dataset = MyDataset(df=train_df, eval_mode=False)\n","train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n","\n","val_dataset = MyDataset(df = val_df, eval_mode=True)\n","val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False)\n","\n","test_dataset = MyDataset(test_df, False)\n","test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=6)\n","\n","class AutoEncoder(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","        self.Encoder = nn.Sequential(\n","            nn.Linear(30,64),\n","            nn.BatchNorm1d(64),\n","            # nn.LayerNorm(64),\n","            nn.LeakyReLU(),\n","            # nn.ReLU(),\n","            nn.Linear(64,128),\n","            nn.BatchNorm1d(128),\n","            # nn.LayerNorm(128),\n","            nn.LeakyReLU(),\n","            # nn.ReLU()\n","        )\n","        self.Decoder = nn.Sequential(\n","            nn.Linear(128,64),\n","            nn.BatchNorm1d(64),\n","            # nn.LayerNorm(64),\n","            nn.LeakyReLU(),\n","            # nn.ReLU(),\n","            nn.Linear(64,30)\n","        )\n","        ########################################\n","        # self.Encoder = nn.Sequential(\n","        #     nn.Linear(30,15),\n","        #     nn.BatchNorm1d(15),\n","        #     nn.LeakyReLU(),\n","        #     nn.Linear(15,10),\n","        #     nn.BatchNorm1d(10),\n","        #     nn.LeakyReLU(),\n","        #     nn.Linear(10,5),\n","        #     nn.BatchNorm1d(5),\n","        #     nn.LeakyReLU()\n","        # )\n","        # self.Decoder = nn.Sequential(\n","        #     nn.Linear(5,10),\n","        #     nn.BatchNorm1d(10),\n","        #     nn.LeakyReLU(),\n","        #     nn.Linear(10,15),\n","        #     nn.BatchNorm1d(15),\n","        #     nn.LeakyReLU(),\n","        #     nn.Linear(15,30)\n","        # )\n","        ########################################\n","        # self.Encoder = nn.Sequential(\n","        #     nn.Linear(30,60),\n","        #     nn.BatchNorm1d(60),\n","        #     nn.LeakyReLU(),\n","        #     nn.Linear(60,120),\n","        #     nn.BatchNorm1d(120),\n","        #     nn.LeakyReLU(),\n","        #     nn.Linear(120, 60),\n","        #     nn.BatchNorm1d(60),\n","        #     nn.LeakyReLU(),\n","        #     nn.Linear(60, 30),\n","        #     nn.BatchNorm1d(30),\n","        #     nn.LeakyReLU(),\n","        #     nn.Linear(30, 5),\n","        #     nn.BatchNorm1d(5),\n","        #     nn.LeakyReLU()\n","        # )\n","        # self.Decoder = nn.Sequential(\n","        #     nn.Linear(5,30),\n","        #     nn.BatchNorm1d(30),\n","        #     nn.LeakyReLU(),\n","        #     nn.Linear(30,60),\n","        #     nn.BatchNorm1d(60),\n","        #     nn.LeakyReLU(),\n","        #     nn.Linear(60,120),\n","        #     nn.BatchNorm1d(120),\n","        #     nn.LeakyReLU(),\n","        #     nn.Linear(120,30)\n","        # )\n","        \n","    def forward(self, x):\n","        x = self.Encoder(x)\n","        x = self.Decoder(x)\n","        return x\n","\n","class Trainer():\n","    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.scheduler = scheduler\n","        self.device = device\n","        # Loss Function\n","        self.criterion = nn.L1Loss().to(self.device)\n","        \n","    def fit(self, ):\n","        self.model.to(self.device)\n","        best_score = 0\n","        for epoch in range(EPOCHS):\n","            self.model.train()\n","            train_loss = []\n","            for x in iter(self.train_loader):\n","                x = x.float().to(self.device)\n","                self.optimizer.zero_grad()\n","\n","                _x = self.model(x)\n","                loss = self.criterion(x, _x)\n","\n","                loss.backward()\n","                self.optimizer.step()\n","\n","                train_loss.append(loss.item())\n","\n","            score = self.validation(self.model, 0.95)\n","            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n","\n","            if self.scheduler is not None:\n","                self.scheduler.step(score)\n","\n","            if best_score < score:\n","                best_score = score\n","                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n","            wandb.log({\n","                \"validation f1\": score\n","            })\n","    \n","    def validation(self, eval_model, thr):\n","        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","        eval_model.eval()\n","        pred = []\n","        true = []\n","        with torch.no_grad():\n","            for x, y in iter(self.val_loader):\n","                x = x.float().to(self.device)\n","\n","                _x = self.model(x)\n","                diff = cos(x, _x).cpu().tolist()\n","                batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n","                pred += batch_pred\n","                true += y.tolist()\n","\n","        return f1_score(true, pred, average='macro')\n","\n","wandb.init()\n","model = nn.DataParallel(AutoEncoder())\n","model.eval()\n","if WD : optimizer = torch.optim.Adam(params = model.parameters(), lr = LR, weight_decay=WD)\n","else : optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n","# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0.1)\n","# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.00005, \n","#                                               step_size_up=5, max_lr=0.0001, \n","#                                               gamma=0.5, mode='exp_range')\n","trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n","trainer.fit()"],"metadata":{"id":"kijk5u73jo-B","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0d6b3de3030e4631ac20da79851f3dc0","5f96a7dec45f48e18cb52a3f38e8899f","1697aa8fa13a4748a03c534a285d88f0","c23508aa891a4ceb9ba7ce95276e260a","a0406b7a0ebf4945b449b5c3d23f8740","da58b0fe54ef47df9fedb0cc91f153d8","e2d54ad84a714341a6e6deaa6c1664c4","25e00f2897dd48a6b6c895416a0862ec"]},"executionInfo":{"status":"ok","timestamp":1659876500082,"user_tz":-540,"elapsed":583903,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"08ae0531-3617-4a98-e566-c53f2394aa73"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:3bhmfayq) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d6b3de3030e4631ac20da79851f3dc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validation f1</td><td>▁▇▇▇█▇██████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validation f1</td><td>0.53942</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">balmy-cosmos-404</strong>: <a href=\"https://wandb.ai/sohyun/uncategorized/runs/3bhmfayq\" target=\"_blank\">https://wandb.ai/sohyun/uncategorized/runs/3bhmfayq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220807_123041-3bhmfayq/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:3bhmfayq). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data/wandb/run-20220807_123839-2k5z73pi</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/sohyun/uncategorized/runs/2k5z73pi\" target=\"_blank\">dark-tree-405</a></strong> to <a href=\"https://wandb.ai/sohyun/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch : [0] Train loss : [0.5504933893680573] Val Score : [0.0014752523784167275])\n","Epoch : [1] Train loss : [0.3603777928011758] Val Score : [0.06484129100843904])\n","Epoch : [2] Train loss : [0.2681117185524532] Val Score : [0.29602032994949545])\n","Epoch : [3] Train loss : [0.21450603221143996] Val Score : [0.4111044055839009])\n","Epoch : [4] Train loss : [0.18204315858227865] Val Score : [0.4465154220118763])\n","Epoch : [5] Train loss : [0.16024331322738103] Val Score : [0.47455413607102637])\n","Epoch : [6] Train loss : [0.14460599422454834] Val Score : [0.48724719278117745])\n","Epoch : [7] Train loss : [0.13275623534406936] Val Score : [0.49429601949436064])\n","Epoch : [8] Train loss : [0.12325334868260793] Val Score : [0.49842777698275637])\n","Epoch : [9] Train loss : [0.11725947047982897] Val Score : [0.5045806247968846])\n","Epoch : [10] Train loss : [0.11233177461794444] Val Score : [0.5067537167017901])\n","Epoch : [11] Train loss : [0.10849422109978539] Val Score : [0.5095524022499065])\n","Epoch : [12] Train loss : [0.10455265534775597] Val Score : [0.5124741646056428])\n","Epoch : [13] Train loss : [0.09978770783969335] Val Score : [0.5156362846083409])\n","Epoch : [14] Train loss : [0.09782436064311437] Val Score : [0.517659362423344])\n","Epoch : [15] Train loss : [0.09620750589030129] Val Score : [0.5189857915912958])\n","Epoch : [16] Train loss : [0.09268484158175332] Val Score : [0.5208394294960612])\n","Epoch : [17] Train loss : [0.08969465323856898] Val Score : [0.5242340976441524])\n","Epoch : [18] Train loss : [0.08584345344986234] Val Score : [0.5259544412021552])\n","Epoch : [19] Train loss : [0.08371979211057935] Val Score : [0.5279734532456781])\n","Epoch : [20] Train loss : [0.08287948902164187] Val Score : [0.5284208127952164])\n","Epoch : [21] Train loss : [0.08074127350534711] Val Score : [0.5298738924878902])\n","Epoch : [22] Train loss : [0.07868405963693346] Val Score : [0.5325910133552555])\n","Epoch : [23] Train loss : [0.07741647639444896] Val Score : [0.5323255107389778])\n","Epoch : [24] Train loss : [0.07592652099473136] Val Score : [0.5350396913539963])\n","Epoch : [25] Train loss : [0.07506399814571653] Val Score : [0.5395917341648675])\n","Epoch : [26] Train loss : [0.07415294115032468] Val Score : [0.5411116199984652])\n","Epoch : [27] Train loss : [0.0724289161818368] Val Score : [0.5425249383473707])\n","Epoch : [28] Train loss : [0.0737070803131376] Val Score : [0.5424284878256398])\n","Epoch : [29] Train loss : [0.07135399537427085] Val Score : [0.5460123351765206])\n","Epoch : [30] Train loss : [0.06974589718239647] Val Score : [0.5499639140767333])\n","Epoch : [31] Train loss : [0.06731681951454707] Val Score : [0.5516194348205763])\n","Epoch : [32] Train loss : [0.06771909445524216] Val Score : [0.5526829003362292])\n","Epoch : [33] Train loss : [0.06585872705493655] Val Score : [0.5516194348205763])\n","Epoch : [34] Train loss : [0.06581090071371623] Val Score : [0.5526829003362292])\n","Epoch : [35] Train loss : [0.06689226201602391] Val Score : [0.5529543625269938])\n","Epoch : [36] Train loss : [0.06573721979345594] Val Score : [0.5574767520808366])\n","Epoch : [37] Train loss : [0.06414088926145009] Val Score : [0.5573209235700024])\n","Epoch : [38] Train loss : [0.06364670608724866] Val Score : [0.5560994112813382])\n","Epoch : [39] Train loss : [0.06453656724521092] Val Score : [0.5597358408644433])\n","Epoch : [40] Train loss : [0.06295764872006007] Val Score : [0.561795386550052])\n","Epoch : [41] Train loss : [0.05999999812671116] Val Score : [0.561795386550052])\n","Epoch : [42] Train loss : [0.05898252874612808] Val Score : [0.5632372725712661])\n","Epoch : [43] Train loss : [0.06001030706933567] Val Score : [0.5647384131310997])\n","Epoch : [44] Train loss : [0.060982112905808857] Val Score : [0.57352295988857])\n","Epoch : [45] Train loss : [0.05871755204030445] Val Score : [0.5778142080957739])\n","Epoch : [46] Train loss : [0.05676253139972687] Val Score : [0.578890323326525])\n","Epoch : [47] Train loss : [0.053642885493380685] Val Score : [0.5946809246376881])\n","Epoch : [48] Train loss : [0.05585588621241706] Val Score : [0.6047512688678767])\n","Epoch : [49] Train loss : [0.05436023111854281] Val Score : [0.6354400298239444])\n","Epoch : [50] Train loss : [0.05493131971785] Val Score : [0.6931029658550301])\n","Epoch : [51] Train loss : [0.05620598580156054] Val Score : [0.7187349645015549])\n","Epoch : [52] Train loss : [0.05528389768941062] Val Score : [0.7112658784551884])\n","Epoch : [53] Train loss : [0.05496952256986073] Val Score : [0.7288385690883094])\n","Epoch : [54] Train loss : [0.050484525838068554] Val Score : [0.7226686263465465])\n","Epoch : [55] Train loss : [0.05067208143217223] Val Score : [0.7206844679680786])\n","Epoch : [56] Train loss : [0.051961948829037805] Val Score : [0.7226686263465465])\n","Epoch : [57] Train loss : [0.05321418015020234] Val Score : [0.7206844679680786])\n","Epoch : [58] Train loss : [0.0547319341983114] Val Score : [0.7246883762645999])\n","Epoch : [59] Train loss : [0.051646055919783454] Val Score : [0.7353562550268086])\n","Epoch : [60] Train loss : [0.05059265451771872] Val Score : [0.7331432493795871])\n","Epoch : [61] Train loss : [0.046103005962712426] Val Score : [0.7399094305905288])\n","Epoch : [62] Train loss : [0.04905534588864872] Val Score : [0.7422520697342344])\n","Epoch : [63] Train loss : [0.0499049217573234] Val Score : [0.7353562550268086])\n","Epoch : [64] Train loss : [0.05102408251592091] Val Score : [0.7376112450647377])\n","Epoch : [65] Train loss : [0.050475710204669406] Val Score : [0.730971061881369])\n","Epoch : [66] Train loss : [0.04960950570447104] Val Score : [0.7399094305905288])\n","Epoch : [67] Train loss : [0.05097536529813494] Val Score : [0.7422520697342344])\n","Epoch : [68] Train loss : [0.050271661153861454] Val Score : [0.7353562550268086])\n","Epoch : [69] Train loss : [0.048472159675189426] Val Score : [0.7353562550268086])\n","Epoch : [70] Train loss : [0.046193570962974] Val Score : [0.7376112450647377])\n","Epoch : [71] Train loss : [0.046346666025263925] Val Score : [0.7399094305905288])\n","Epoch : [72] Train loss : [0.04594614942158971] Val Score : [0.7573184229436457])\n","Epoch : [73] Train loss : [0.0450226047209331] Val Score : [0.7353562550268086])\n","Epoch : [74] Train loss : [0.04798642971685955] Val Score : [0.7600119366040216])\n","Epoch : [75] Train loss : [0.04842704002346311] Val Score : [0.75467969893057])\n","Epoch : [76] Train loss : [0.04418753193957465] Val Score : [0.762761970120889])\n","Epoch : [77] Train loss : [0.04320730268955231] Val Score : [0.7495600450513867])\n","Epoch : [78] Train loss : [0.045965838113001416] Val Score : [0.7573184229436457])\n","Epoch : [79] Train loss : [0.04801170048969133] Val Score : [0.7600119366040216])\n","Epoch : [80] Train loss : [0.04181905995522227] Val Score : [0.7495600450513867])\n","Epoch : [81] Train loss : [0.04435924334185464] Val Score : [0.7655703273293624])\n","Epoch : [82] Train loss : [0.04884791374206543] Val Score : [0.7684388896488608])\n","Epoch : [83] Train loss : [0.04694605725152152] Val Score : [0.752094104263044])\n","Epoch : [84] Train loss : [0.04526072953428541] Val Score : [0.7684388896488608])\n","Epoch : [85] Train loss : [0.04726322793534824] Val Score : [0.7600119366040216])\n","Epoch : [86] Train loss : [0.044967017003468106] Val Score : [0.7655703273293624])\n","Epoch : [87] Train loss : [0.044153183698654175] Val Score : [0.7743645687973808])\n","Epoch : [88] Train loss : [0.04198955904160227] Val Score : [0.777425875747303])\n","Epoch : [89] Train loss : [0.04434130181159292] Val Score : [0.7684388896488608])\n","Epoch : [90] Train loss : [0.04534392484596798] Val Score : [0.7870308296420961])\n","Epoch : [91] Train loss : [0.045373374330145974] Val Score : [0.7837566139258728])\n","Epoch : [92] Train loss : [0.046244483441114426] Val Score : [0.79380975986869])\n","Epoch : [93] Train loss : [0.04516605553882463] Val Score : [0.7903809848799157])\n","Epoch : [94] Train loss : [0.04177745644535337] Val Score : [0.7870308296420961])\n","Epoch : [95] Train loss : [0.04405388768230166] Val Score : [0.7973199624677456])\n","Epoch : [96] Train loss : [0.04055637014763696] Val Score : [0.79380975986869])\n","Epoch : [97] Train loss : [0.04086238890886307] Val Score : [0.8045965667777433])\n","Epoch : [98] Train loss : [0.04071000963449478] Val Score : [0.8045965667777433])\n","Epoch : [99] Train loss : [0.04086933923619134] Val Score : [0.808369294415656])\n","Epoch : [100] Train loss : [0.04222440666386059] Val Score : [0.8376267560436427])\n","Epoch : [101] Train loss : [0.04130195506981441] Val Score : [0.8422634702634115])\n","Epoch : [102] Train loss : [0.04132922259824617] Val Score : [0.856966968023358])\n","Epoch : [103] Train loss : [0.041245748421975544] Val Score : [0.8621517488551477])\n","Epoch : [104] Train loss : [0.04417049938014576] Val Score : [0.890501890608512])\n","Epoch : [105] Train loss : [0.042145186236926487] Val Score : [0.8967110829723166])\n","Epoch : [106] Train loss : [0.042012083743299754] Val Score : [0.9031202878275757])\n","Epoch : [107] Train loss : [0.04064929538539478] Val Score : [0.9031202878275757])\n","Epoch : [108] Train loss : [0.03855669392006738] Val Score : [0.9097393418694286])\n","Epoch : [109] Train loss : [0.03930177912116051] Val Score : [0.9097393418694286])\n","Epoch : [110] Train loss : [0.03827536212546485] Val Score : [0.9097393418694286])\n","Epoch : [111] Train loss : [0.04045232757925987] Val Score : [0.9097393418694286])\n","Epoch : [112] Train loss : [0.04063024052551815] Val Score : [0.9165787375726882])\n","Epoch : [113] Train loss : [0.040102540382317135] Val Score : [0.9165787375726882])\n","Epoch : [114] Train loss : [0.0382083851311888] Val Score : [0.9165787375726882])\n","Epoch : [115] Train loss : [0.03979470634034702] Val Score : [0.9165787375726882])\n","Epoch : [116] Train loss : [0.040651577923979075] Val Score : [0.9165787375726882])\n","Epoch : [117] Train loss : [0.037919585193906515] Val Score : [0.9165787375726882])\n","Epoch : [118] Train loss : [0.039182389953306744] Val Score : [0.9165787375726882])\n","Epoch : [119] Train loss : [0.03851830852883203] Val Score : [0.9165787375726882])\n","Epoch : [120] Train loss : [0.03804876282811165] Val Score : [0.9165787375726882])\n","Epoch : [121] Train loss : [0.04066556053502219] Val Score : [0.9165787375726882])\n","Epoch : [122] Train loss : [0.04105628973671368] Val Score : [0.9165787375726882])\n","Epoch : [123] Train loss : [0.03750065022281238] Val Score : [0.9165787375726882])\n","Epoch 00124: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch : [124] Train loss : [0.031066966642226492] Val Score : [0.9165787375726882])\n","Epoch : [125] Train loss : [0.03170343515064035] Val Score : [0.9165787375726882])\n","Epoch : [126] Train loss : [0.029446154034563472] Val Score : [0.9165787375726882])\n","Epoch : [127] Train loss : [0.02906191162765026] Val Score : [0.9165787375726882])\n","Epoch : [128] Train loss : [0.028881086834839413] Val Score : [0.9165787375726882])\n","Epoch : [129] Train loss : [0.028404351057750837] Val Score : [0.9165787375726882])\n","Epoch : [130] Train loss : [0.027902867112840925] Val Score : [0.9165787375726882])\n","Epoch : [131] Train loss : [0.029583470097609928] Val Score : [0.9165787375726882])\n","Epoch : [132] Train loss : [0.030936792758958682] Val Score : [0.9165787375726882])\n","Epoch : [133] Train loss : [0.030234614121062413] Val Score : [0.9165787375726882])\n","Epoch : [134] Train loss : [0.02835875004529953] Val Score : [0.9165787375726882])\n","Epoch 00135: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch : [135] Train loss : [0.025114191429955617] Val Score : [0.9165787375726882])\n","Epoch : [136] Train loss : [0.02498259475188596] Val Score : [0.9165787375726882])\n","Epoch : [137] Train loss : [0.02528689508991582] Val Score : [0.9165787375726882])\n","Epoch : [138] Train loss : [0.024405538769704953] Val Score : [0.9165787375726882])\n","Epoch : [139] Train loss : [0.02528514207473823] Val Score : [0.9165787375726882])\n","Epoch : [140] Train loss : [0.025221806285636767] Val Score : [0.9165787375726882])\n","Epoch : [141] Train loss : [0.024857958778738976] Val Score : [0.9165787375726882])\n","Epoch : [142] Train loss : [0.024897344942603792] Val Score : [0.9165787375726882])\n","Epoch : [143] Train loss : [0.02391891394342695] Val Score : [0.9165787375726882])\n","Epoch : [144] Train loss : [0.024888578270162855] Val Score : [0.9165787375726882])\n","Epoch : [145] Train loss : [0.024874558406216756] Val Score : [0.9165787375726882])\n","Epoch 00146: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch : [146] Train loss : [0.023960307240486145] Val Score : [0.9165787375726882])\n","Epoch : [147] Train loss : [0.02204423743699278] Val Score : [0.9165787375726882])\n","Epoch : [148] Train loss : [0.02181886455842427] Val Score : [0.9165787375726882])\n","Epoch : [149] Train loss : [0.022500693798065186] Val Score : [0.9165787375726882])\n","Epoch : [150] Train loss : [0.021277492067643573] Val Score : [0.9165787375726882])\n","Epoch : [151] Train loss : [0.019621256472808973] Val Score : [0.9165787375726882])\n","Epoch : [152] Train loss : [0.020582001922386035] Val Score : [0.9165787375726882])\n","Epoch : [153] Train loss : [0.019542098311441287] Val Score : [0.9165787375726882])\n","Epoch : [154] Train loss : [0.020997710525989532] Val Score : [0.9165787375726882])\n","Epoch : [155] Train loss : [0.020626589123691832] Val Score : [0.9165787375726882])\n","Epoch : [156] Train loss : [0.02180872272167887] Val Score : [0.9165787375726882])\n","Epoch 00157: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch : [157] Train loss : [0.0206453339861972] Val Score : [0.9165787375726882])\n","Epoch : [158] Train loss : [0.0189953190939767] Val Score : [0.9165787375726882])\n","Epoch : [159] Train loss : [0.02021493496639388] Val Score : [0.9165787375726882])\n","Epoch : [160] Train loss : [0.0192914003772395] Val Score : [0.9165787375726882])\n","Epoch : [161] Train loss : [0.02026773457016264] Val Score : [0.9165787375726882])\n","Epoch : [162] Train loss : [0.02090569239641939] Val Score : [0.9165787375726882])\n","Epoch : [163] Train loss : [0.019080556130834987] Val Score : [0.9165787375726882])\n","Epoch : [164] Train loss : [0.018310493656567166] Val Score : [0.9165787375726882])\n","Epoch : [165] Train loss : [0.020471977069973946] Val Score : [0.9165787375726882])\n","Epoch : [166] Train loss : [0.02068325611097472] Val Score : [0.9165787375726882])\n","Epoch : [167] Train loss : [0.019583447969385555] Val Score : [0.9165787375726882])\n","Epoch 00168: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch : [168] Train loss : [0.019387587372745787] Val Score : [0.9165787375726882])\n","Epoch : [169] Train loss : [0.018786695918866565] Val Score : [0.9165787375726882])\n","Epoch : [170] Train loss : [0.018917756554271494] Val Score : [0.9165787375726882])\n","Epoch : [171] Train loss : [0.019682889272059714] Val Score : [0.9165787375726882])\n","Epoch : [172] Train loss : [0.017479277348944118] Val Score : [0.9165787375726882])\n","Epoch : [173] Train loss : [0.01946252291756017] Val Score : [0.9165787375726882])\n","Epoch : [174] Train loss : [0.0201478193381003] Val Score : [0.9165787375726882])\n","Epoch : [175] Train loss : [0.020087192367230142] Val Score : [0.9165787375726882])\n","Epoch : [176] Train loss : [0.018985556970749582] Val Score : [0.9165787375726882])\n","Epoch : [177] Train loss : [0.01828874115433012] Val Score : [0.9165787375726882])\n","Epoch : [178] Train loss : [0.017906291144234792] Val Score : [0.9165787375726882])\n","Epoch 00179: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch : [179] Train loss : [0.01946019008755684] Val Score : [0.9165787375726882])\n","Epoch : [180] Train loss : [0.017694091956530298] Val Score : [0.9165787375726882])\n","Epoch : [181] Train loss : [0.018654946769986833] Val Score : [0.9165787375726882])\n","Epoch : [182] Train loss : [0.01774194317736796] Val Score : [0.9165787375726882])\n","Epoch : [183] Train loss : [0.01924498485667365] Val Score : [0.9165787375726882])\n","Epoch : [184] Train loss : [0.01826850644179753] Val Score : [0.9165787375726882])\n","Epoch : [185] Train loss : [0.0182031389059765] Val Score : [0.9165787375726882])\n","Epoch : [186] Train loss : [0.018850546862397875] Val Score : [0.9165787375726882])\n","Epoch : [187] Train loss : [0.018375565830085958] Val Score : [0.9165787375726882])\n","Epoch : [188] Train loss : [0.018828988075256348] Val Score : [0.9165787375726882])\n","Epoch : [189] Train loss : [0.017882653645106723] Val Score : [0.9165787375726882])\n","Epoch 00190: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch : [190] Train loss : [0.01853837338941438] Val Score : [0.9165787375726882])\n","Epoch : [191] Train loss : [0.01808036757366998] Val Score : [0.9165787375726882])\n","Epoch : [192] Train loss : [0.01889745465346745] Val Score : [0.9165787375726882])\n","Epoch : [193] Train loss : [0.018470792632017816] Val Score : [0.9165787375726882])\n","Epoch : [194] Train loss : [0.018945560125367984] Val Score : [0.9165787375726882])\n","Epoch : [195] Train loss : [0.017540490520851954] Val Score : [0.9165787375726882])\n","Epoch : [196] Train loss : [0.017078621046883718] Val Score : [0.9165787375726882])\n","Epoch : [197] Train loss : [0.019113241029637202] Val Score : [0.9165787375726882])\n","Epoch : [198] Train loss : [0.01829470188489982] Val Score : [0.9165787375726882])\n","Epoch : [199] Train loss : [0.017410643930946077] Val Score : [0.9165787375726882])\n","Epoch : [200] Train loss : [0.01789996533521584] Val Score : [0.9165787375726882])\n","Epoch 00201: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch : [201] Train loss : [0.018041772235717093] Val Score : [0.9165787375726882])\n","Epoch : [202] Train loss : [0.01798172907105514] Val Score : [0.9165787375726882])\n","Epoch : [203] Train loss : [0.018282354410205568] Val Score : [0.9165787375726882])\n","Epoch : [204] Train loss : [0.018305831189666475] Val Score : [0.9165787375726882])\n","Epoch : [205] Train loss : [0.01729187901530947] Val Score : [0.9165787375726882])\n","Epoch : [206] Train loss : [0.017764308090720857] Val Score : [0.9165787375726882])\n","Epoch : [207] Train loss : [0.017118788191250393] Val Score : [0.9165787375726882])\n","Epoch : [208] Train loss : [0.017389863463384763] Val Score : [0.9165787375726882])\n","Epoch : [209] Train loss : [0.01831054195229496] Val Score : [0.9165787375726882])\n","Epoch : [210] Train loss : [0.017743658407458236] Val Score : [0.9165787375726882])\n","Epoch : [211] Train loss : [0.01775128221405404] Val Score : [0.9165787375726882])\n","Epoch 00212: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch : [212] Train loss : [0.018895616488797323] Val Score : [0.9165787375726882])\n","Epoch : [213] Train loss : [0.018250959260123118] Val Score : [0.9165787375726882])\n","Epoch : [214] Train loss : [0.017614214281950678] Val Score : [0.9165787375726882])\n","Epoch : [215] Train loss : [0.018802186474204063] Val Score : [0.9165787375726882])\n","Epoch : [216] Train loss : [0.017247008425848826] Val Score : [0.9165787375726882])\n","Epoch : [217] Train loss : [0.017530031635292938] Val Score : [0.9165787375726882])\n","Epoch : [218] Train loss : [0.018265618942677975] Val Score : [0.9165787375726882])\n","Epoch : [219] Train loss : [0.018492004834115505] Val Score : [0.9165787375726882])\n","Epoch : [220] Train loss : [0.01672509911337069] Val Score : [0.9165787375726882])\n","Epoch : [221] Train loss : [0.0178972456072058] Val Score : [0.9165787375726882])\n","Epoch : [222] Train loss : [0.016606660692819526] Val Score : [0.9165787375726882])\n","Epoch 00223: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch : [223] Train loss : [0.017622857221535275] Val Score : [0.9165787375726882])\n","Epoch : [224] Train loss : [0.02049604750105313] Val Score : [0.9165787375726882])\n","Epoch : [225] Train loss : [0.017865114712289402] Val Score : [0.9165787375726882])\n","Epoch : [226] Train loss : [0.01664166391960212] Val Score : [0.9165787375726882])\n","Epoch : [227] Train loss : [0.01773571435894285] Val Score : [0.9165787375726882])\n","Epoch : [228] Train loss : [0.01744274449135576] Val Score : [0.9165787375726882])\n","Epoch : [229] Train loss : [0.01833293374095644] Val Score : [0.9165787375726882])\n","Epoch : [230] Train loss : [0.018029358371027877] Val Score : [0.9165787375726882])\n","Epoch : [231] Train loss : [0.01754628068634442] Val Score : [0.9165787375726882])\n","Epoch : [232] Train loss : [0.0180287454277277] Val Score : [0.9165787375726882])\n","Epoch : [233] Train loss : [0.01888991945556232] Val Score : [0.9165787375726882])\n","Epoch 00234: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch : [234] Train loss : [0.016593033846999918] Val Score : [0.9165787375726882])\n","Epoch : [235] Train loss : [0.019677622243762016] Val Score : [0.9165787375726882])\n","Epoch : [236] Train loss : [0.019171821219580516] Val Score : [0.9165787375726882])\n","Epoch : [237] Train loss : [0.017443037991012846] Val Score : [0.9165787375726882])\n","Epoch : [238] Train loss : [0.016849381316985403] Val Score : [0.9165787375726882])\n","Epoch : [239] Train loss : [0.019098236624683653] Val Score : [0.9165787375726882])\n","Epoch : [240] Train loss : [0.017307284953338758] Val Score : [0.9165787375726882])\n","Epoch : [241] Train loss : [0.016926160880497525] Val Score : [0.9165787375726882])\n","Epoch : [242] Train loss : [0.017847380733915737] Val Score : [0.9165787375726882])\n","Epoch : [243] Train loss : [0.019035486238343374] Val Score : [0.9165787375726882])\n","Epoch : [244] Train loss : [0.01895819418132305] Val Score : [0.9165787375726882])\n","Epoch 00245: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch : [245] Train loss : [0.016836045842085565] Val Score : [0.9165787375726882])\n","Epoch : [246] Train loss : [0.018671829785619463] Val Score : [0.9165787375726882])\n","Epoch : [247] Train loss : [0.017937436300729002] Val Score : [0.9165787375726882])\n","Epoch : [248] Train loss : [0.017213850814316953] Val Score : [0.9165787375726882])\n","Epoch : [249] Train loss : [0.01905380641775472] Val Score : [0.9165787375726882])\n","Epoch : [250] Train loss : [0.01639430584119899] Val Score : [0.9165787375726882])\n","Epoch : [251] Train loss : [0.0172404855755823] Val Score : [0.9165787375726882])\n","Epoch : [252] Train loss : [0.01865116094372102] Val Score : [0.9165787375726882])\n","Epoch : [253] Train loss : [0.01830870165888752] Val Score : [0.9165787375726882])\n","Epoch : [254] Train loss : [0.01811775006353855] Val Score : [0.9165787375726882])\n","Epoch : [255] Train loss : [0.01764626827623163] Val Score : [0.9165787375726882])\n","Epoch 00256: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch : [256] Train loss : [0.01896645554474422] Val Score : [0.9165787375726882])\n","Epoch : [257] Train loss : [0.017742390877434185] Val Score : [0.9165787375726882])\n","Epoch : [258] Train loss : [0.019831592749272074] Val Score : [0.9165787375726882])\n","Epoch : [259] Train loss : [0.01845026934253318] Val Score : [0.9165787375726882])\n","Epoch : [260] Train loss : [0.018050130057547773] Val Score : [0.9165787375726882])\n","Epoch : [261] Train loss : [0.017022213765553067] Val Score : [0.9165787375726882])\n","Epoch : [262] Train loss : [0.01707770289587123] Val Score : [0.9165787375726882])\n","Epoch : [263] Train loss : [0.018993352938975607] Val Score : [0.9165787375726882])\n","Epoch : [264] Train loss : [0.017809309464480196] Val Score : [0.9165787375726882])\n","Epoch : [265] Train loss : [0.016863915670130934] Val Score : [0.9165787375726882])\n","Epoch : [266] Train loss : [0.01803888407136713] Val Score : [0.9165787375726882])\n","Epoch 00267: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch : [267] Train loss : [0.018691267019936016] Val Score : [0.9165787375726882])\n","Epoch : [268] Train loss : [0.018187241362673894] Val Score : [0.9165787375726882])\n","Epoch : [269] Train loss : [0.016586072210754668] Val Score : [0.9165787375726882])\n","Epoch : [270] Train loss : [0.018413428350218704] Val Score : [0.9165787375726882])\n","Epoch : [271] Train loss : [0.018038919727717127] Val Score : [0.9165787375726882])\n","Epoch : [272] Train loss : [0.018103664740920067] Val Score : [0.9165787375726882])\n","Epoch : [273] Train loss : [0.01831900833972863] Val Score : [0.9165787375726882])\n","Epoch : [274] Train loss : [0.01906901119010789] Val Score : [0.9165787375726882])\n","Epoch : [275] Train loss : [0.017324901052883694] Val Score : [0.9165787375726882])\n","Epoch : [276] Train loss : [0.018736571206578186] Val Score : [0.9165787375726882])\n","Epoch : [277] Train loss : [0.01838594488799572] Val Score : [0.9165787375726882])\n","Epoch 00278: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch : [278] Train loss : [0.019403931285653795] Val Score : [0.9165787375726882])\n","Epoch : [279] Train loss : [0.016534611183617796] Val Score : [0.9165787375726882])\n","Epoch : [280] Train loss : [0.0193377145166908] Val Score : [0.9165787375726882])\n","Epoch : [281] Train loss : [0.01694213692098856] Val Score : [0.9165787375726882])\n","Epoch : [282] Train loss : [0.01793063565024308] Val Score : [0.9165787375726882])\n","Epoch : [283] Train loss : [0.016962831307734762] Val Score : [0.9165787375726882])\n","Epoch : [284] Train loss : [0.018778312685234205] Val Score : [0.9165787375726882])\n","Epoch : [285] Train loss : [0.018565984442830086] Val Score : [0.9165787375726882])\n","Epoch : [286] Train loss : [0.017363989459616796] Val Score : [0.9165787375726882])\n","Epoch : [287] Train loss : [0.019038379059306214] Val Score : [0.9165787375726882])\n","Epoch : [288] Train loss : [0.019015869790954248] Val Score : [0.9165787375726882])\n","Epoch 00289: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch : [289] Train loss : [0.018123931384512355] Val Score : [0.9165787375726882])\n","Epoch : [290] Train loss : [0.019845642681632723] Val Score : [0.9165787375726882])\n","Epoch : [291] Train loss : [0.017153605818748474] Val Score : [0.9165787375726882])\n","Epoch : [292] Train loss : [0.01817156986466476] Val Score : [0.9165787375726882])\n","Epoch : [293] Train loss : [0.01747534716767924] Val Score : [0.9165787375726882])\n","Epoch : [294] Train loss : [0.01780191489628383] Val Score : [0.9165787375726882])\n","Epoch : [295] Train loss : [0.018400938915354863] Val Score : [0.9165787375726882])\n","Epoch : [296] Train loss : [0.01901776609676225] Val Score : [0.9165787375726882])\n","Epoch : [297] Train loss : [0.018028638192585537] Val Score : [0.9165787375726882])\n","Epoch : [298] Train loss : [0.017507314948099] Val Score : [0.9165787375726882])\n","Epoch : [299] Train loss : [0.018693068463887488] Val Score : [0.9165787375726882])\n","Epoch 00300: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch : [300] Train loss : [0.018351106771400998] Val Score : [0.9165787375726882])\n","Epoch : [301] Train loss : [0.017831447401217053] Val Score : [0.9165787375726882])\n","Epoch : [302] Train loss : [0.019514218238847598] Val Score : [0.9165787375726882])\n","Epoch : [303] Train loss : [0.018004314973950386] Val Score : [0.9165787375726882])\n","Epoch : [304] Train loss : [0.019624777138233185] Val Score : [0.9165787375726882])\n","Epoch : [305] Train loss : [0.017225555277296474] Val Score : [0.9165787375726882])\n","Epoch : [306] Train loss : [0.019923537703497068] Val Score : [0.9165787375726882])\n","Epoch : [307] Train loss : [0.017485779843160083] Val Score : [0.9165787375726882])\n","Epoch : [308] Train loss : [0.018002637795039585] Val Score : [0.9165787375726882])\n","Epoch : [309] Train loss : [0.017301156850797788] Val Score : [0.9165787375726882])\n","Epoch : [310] Train loss : [0.016919081498469626] Val Score : [0.9165787375726882])\n","Epoch 00311: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch : [311] Train loss : [0.01728482491203717] Val Score : [0.9165787375726882])\n","Epoch : [312] Train loss : [0.01760845977280821] Val Score : [0.9165787375726882])\n","Epoch : [313] Train loss : [0.018583199807575772] Val Score : [0.9165787375726882])\n","Epoch : [314] Train loss : [0.018501569916095053] Val Score : [0.9165787375726882])\n","Epoch : [315] Train loss : [0.018459437681095942] Val Score : [0.9165787375726882])\n","Epoch : [316] Train loss : [0.0191086083650589] Val Score : [0.9165787375726882])\n","Epoch : [317] Train loss : [0.01972140744328499] Val Score : [0.9165787375726882])\n","Epoch : [318] Train loss : [0.018721128946968486] Val Score : [0.9165787375726882])\n","Epoch : [319] Train loss : [0.01655080887888159] Val Score : [0.9165787375726882])\n","Epoch : [320] Train loss : [0.018305057526699135] Val Score : [0.9165787375726882])\n","Epoch : [321] Train loss : [0.01906555292329618] Val Score : [0.9165787375726882])\n","Epoch 00322: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [322] Train loss : [0.018725444562733173] Val Score : [0.9165787375726882])\n","Epoch : [323] Train loss : [0.01733872533908912] Val Score : [0.9165787375726882])\n","Epoch : [324] Train loss : [0.017397586522357806] Val Score : [0.9165787375726882])\n","Epoch : [325] Train loss : [0.017438295696462904] Val Score : [0.9165787375726882])\n","Epoch : [326] Train loss : [0.01797167823782989] Val Score : [0.9165787375726882])\n","Epoch : [327] Train loss : [0.01859706294323717] Val Score : [0.9165787375726882])\n","Epoch : [328] Train loss : [0.01849005264895303] Val Score : [0.9165787375726882])\n","Epoch : [329] Train loss : [0.01796372314648969] Val Score : [0.9165787375726882])\n","Epoch : [330] Train loss : [0.019400357268750668] Val Score : [0.9165787375726882])\n","Epoch : [331] Train loss : [0.0182541659367936] Val Score : [0.9165787375726882])\n","Epoch : [332] Train loss : [0.01729548695896353] Val Score : [0.9165787375726882])\n","Epoch : [333] Train loss : [0.017509504620518004] Val Score : [0.9165787375726882])\n","Epoch : [334] Train loss : [0.018846752920321057] Val Score : [0.9165787375726882])\n","Epoch : [335] Train loss : [0.017912858564938818] Val Score : [0.9165787375726882])\n","Epoch : [336] Train loss : [0.017342371866106987] Val Score : [0.9165787375726882])\n","Epoch : [337] Train loss : [0.01768024797950472] Val Score : [0.9165787375726882])\n","Epoch : [338] Train loss : [0.019717859902552197] Val Score : [0.9165787375726882])\n","Epoch : [339] Train loss : [0.017674931857202734] Val Score : [0.9165787375726882])\n","Epoch : [340] Train loss : [0.017681440338492393] Val Score : [0.9165787375726882])\n","Epoch : [341] Train loss : [0.018358475927795683] Val Score : [0.9165787375726882])\n","Epoch : [342] Train loss : [0.017102050728031566] Val Score : [0.9165787375726882])\n","Epoch : [343] Train loss : [0.018107513897120953] Val Score : [0.9165787375726882])\n","Epoch : [344] Train loss : [0.017062299086579254] Val Score : [0.9165787375726882])\n","Epoch : [345] Train loss : [0.017488123449896063] Val Score : [0.9165787375726882])\n","Epoch : [346] Train loss : [0.01744738899703537] Val Score : [0.9165787375726882])\n","Epoch : [347] Train loss : [0.018891953996249607] Val Score : [0.9165787375726882])\n","Epoch : [348] Train loss : [0.01711540043886219] Val Score : [0.9165787375726882])\n","Epoch : [349] Train loss : [0.01911079484437193] Val Score : [0.9165787375726882])\n","Epoch : [350] Train loss : [0.018734112648027285] Val Score : [0.9165787375726882])\n","Epoch : [351] Train loss : [0.01713140428598438] Val Score : [0.9165787375726882])\n","Epoch : [352] Train loss : [0.018577759819371358] Val Score : [0.9165787375726882])\n","Epoch : [353] Train loss : [0.016842539821352278] Val Score : [0.9165787375726882])\n","Epoch : [354] Train loss : [0.018005901415433203] Val Score : [0.9165787375726882])\n","Epoch : [355] Train loss : [0.018959652366382734] Val Score : [0.9165787375726882])\n","Epoch : [356] Train loss : [0.020265360761966025] Val Score : [0.9165787375726882])\n","Epoch : [357] Train loss : [0.018487236462533474] Val Score : [0.9165787375726882])\n","Epoch : [358] Train loss : [0.018798924450363432] Val Score : [0.9165787375726882])\n","Epoch : [359] Train loss : [0.018688926872398173] Val Score : [0.9165787375726882])\n","Epoch : [360] Train loss : [0.017035783401557376] Val Score : [0.9165787375726882])\n","Epoch : [361] Train loss : [0.017217159936470643] Val Score : [0.9165787375726882])\n","Epoch : [362] Train loss : [0.0173037906310388] Val Score : [0.9165787375726882])\n","Epoch : [363] Train loss : [0.017474949093801633] Val Score : [0.9165787375726882])\n","Epoch : [364] Train loss : [0.017259887818779265] Val Score : [0.9165787375726882])\n","Epoch : [365] Train loss : [0.01803667444203581] Val Score : [0.9165787375726882])\n","Epoch : [366] Train loss : [0.017438587599567006] Val Score : [0.9165787375726882])\n","Epoch : [367] Train loss : [0.018912428058683872] Val Score : [0.9165787375726882])\n","Epoch : [368] Train loss : [0.017653527270470346] Val Score : [0.9165787375726882])\n","Epoch : [369] Train loss : [0.01900708196418626] Val Score : [0.9165787375726882])\n","Epoch : [370] Train loss : [0.018146159127354622] Val Score : [0.9165787375726882])\n","Epoch : [371] Train loss : [0.01722114852496556] Val Score : [0.9165787375726882])\n","Epoch : [372] Train loss : [0.016751602558153018] Val Score : [0.9165787375726882])\n","Epoch : [373] Train loss : [0.017277726903557777] Val Score : [0.9165787375726882])\n","Epoch : [374] Train loss : [0.018088979380471364] Val Score : [0.9165787375726882])\n","Epoch : [375] Train loss : [0.017772453304912363] Val Score : [0.9165787375726882])\n","Epoch : [376] Train loss : [0.01765242964029312] Val Score : [0.9165787375726882])\n","Epoch : [377] Train loss : [0.018290825188159943] Val Score : [0.9165787375726882])\n","Epoch : [378] Train loss : [0.017757562920451164] Val Score : [0.9165787375726882])\n","Epoch : [379] Train loss : [0.018001924934131757] Val Score : [0.9165787375726882])\n","Epoch : [380] Train loss : [0.01826786276485239] Val Score : [0.9165787375726882])\n","Epoch : [381] Train loss : [0.017548227416617528] Val Score : [0.9165787375726882])\n","Epoch : [382] Train loss : [0.017108282340424403] Val Score : [0.9165787375726882])\n","Epoch : [383] Train loss : [0.017361616183604513] Val Score : [0.9165787375726882])\n","Epoch : [384] Train loss : [0.01776700732963426] Val Score : [0.9165787375726882])\n","Epoch : [385] Train loss : [0.017588532529771328] Val Score : [0.9165787375726882])\n","Epoch : [386] Train loss : [0.017812480351754596] Val Score : [0.9165787375726882])\n","Epoch : [387] Train loss : [0.018090889922210147] Val Score : [0.9165787375726882])\n","Epoch : [388] Train loss : [0.017131157352456024] Val Score : [0.9165787375726882])\n","Epoch : [389] Train loss : [0.017373483095850264] Val Score : [0.9165787375726882])\n","Epoch : [390] Train loss : [0.017925545440188477] Val Score : [0.9165787375726882])\n","Epoch : [391] Train loss : [0.0186201666614839] Val Score : [0.9165787375726882])\n","Epoch : [392] Train loss : [0.017435039526649883] Val Score : [0.9165787375726882])\n","Epoch : [393] Train loss : [0.01843824184366635] Val Score : [0.9165787375726882])\n","Epoch : [394] Train loss : [0.018280362311218466] Val Score : [0.9165787375726882])\n","Epoch : [395] Train loss : [0.018066021214638437] Val Score : [0.9165787375726882])\n","Epoch : [396] Train loss : [0.017382228480918065] Val Score : [0.9165787375726882])\n","Epoch : [397] Train loss : [0.018318309847797667] Val Score : [0.9165787375726882])\n","Epoch : [398] Train loss : [0.017288949074489728] Val Score : [0.9165787375726882])\n","Epoch : [399] Train loss : [0.01711967188332762] Val Score : [0.9165787375726882])\n"]}]},{"cell_type":"code","source":["# for test\n","model = AutoEncoder()\n","model.load_state_dict(torch.load('./best_model.pth'))\n","model = nn.DataParallel(model)\n","model.eval()\n","\n","def prediction(model, thr, test_loader, device):\n","    model.to(device)\n","    model.eval()\n","    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","    pred = []\n","    with torch.no_grad():\n","        for x in iter(test_loader):\n","            x = x.float().to(device)\n","            \n","            _x = model(x)\n","            \n","            diff = cos(x, _x).cpu().tolist()\n","            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n","            pred += batch_pred\n","    return pred\n","\n","preds = prediction(model, 0.97, test_loader, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOLXoEwK8TqY","executionInfo":{"status":"ok","timestamp":1657790072472,"user_tz":-540,"elapsed":2848,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"32c4af9c-5b8b-4beb-e760-db42aecb884b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["sum(preds),sum(preds)/len(test_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lnpOcqhM8ex8","executionInfo":{"status":"ok","timestamp":1657790081762,"user_tz":-540,"elapsed":372,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"b27cce99-ea9a-4e55-b665-5517a6b5bb67"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(322, 0.002259601552248023)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":[""],"metadata":{"id":"40CdNVAF8keG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submit = pd.read_csv('./sample_submission.csv')\n","submit['Class'] = preds\n","submit.to_csv('./submit_autoencoder2.csv', index=False)"],"metadata":{"id":"IgdZWXD0IJkR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from mpl_toolkits.mplot3d import Axes3D\n","# import matplotlib.pyplot as plt\n","# %matplotlib notebook\n","# fig = plt.figure()\n","# ax = fig.add_subplot(111, projection='3d')\n","# ax.scatter(test_z[:,1],test_z[:,0], test_z[:,2], c=test_labels.astype(int))\n","# ax.set_xlabel('Encoded')\n","# ax.set_ylabel('Euclidean')\n","# ax.set_zlabel('Cosine')\n","# plt.show()"],"metadata":{"id":"mSenGm1oJFWH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","train_df = pd.read_csv('./train.csv')\n","train_df = train_df.drop(columns=['ID'])\n","val_df = pd.read_csv('./val.csv')\n","val_df = val_df.drop(columns=['ID'])\n","test_df = pd.read_csv('./test.csv')\n","test_df = test_df.drop(columns=['ID'])"],"metadata":{"id":"XklCKI0Fx07f","executionInfo":{"status":"ok","timestamp":1659874889031,"user_tz":-540,"elapsed":5030,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"G0AGErRcx6G_","executionInfo":{"status":"ok","timestamp":1659874894005,"user_tz":-540,"elapsed":386,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"g7HGaacVycj8","executionInfo":{"status":"ok","timestamp":1659874915426,"user_tz":-540,"elapsed":19945,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"DtmJ1y9I6Fug","executionInfo":{"status":"ok","timestamp":1659874938812,"user_tz":-540,"elapsed":371,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"lgTy8eoH2gie"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"opZYw1HK1QKw"},"execution_count":null,"outputs":[]}]}